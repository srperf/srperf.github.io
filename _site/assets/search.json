

[
  
  
    
    
      {
        "title": "7questions",
        "excerpt": "7 QUESTIONS BEFORE PERFORMANCE TEST PROJECTS\n\n\n",
        "content": "7 QUESTIONS BEFORE PERFORMANCE TEST PROJECTS\n\n\n\nSo many times, muchas, I have been thrown into performance load testing projects where there seems to be no sense to why we are hitting that piñata with an Indiana whip. Neither why there are no tamales in the party and everybody is getting tacos on a hard thing that is like a folded tostada. Just nonsense!\n\nThis happens often because the project just got rushed into starting. Just to be able to release the product. Because someone said that to release they had to do a performance something. And then I end up scripting a billion functional test cases using spreadshits to execute everything.\n\nThis often happens because no one asked and answered the following super important questions that every performance testing project needs. And maybe every other project needs them too.\n\nWHY\n\nMost important thing as it defines the plan. Why are we doing this to ourselves? That will change a lot the way we do the things from that point on. What is the party about? If it is a wedding we will need a priest, mariachi, salsa music and a white puffy dress and only one guy in a tuxedo.\n\nIf it is a quince años party we will need Waltz music, maybe mariachi, fifteen young fellows in a tuxedo and one incredibly puffy bright pink shiny dress. Otherwise if it is just your kid’s birthday party, then no mariachi, no puffy dresses and lots of piñatas please!\n\nThe same here the things to do on the project will change a lot depending on why are we doing this. Is it a new software release? Or they are expecting more people to jump on and start using an existing application? Are they suddenly opening the ticket sale for the one time concert of the hottest band in history?\n\nYou are changing your server from the GameStation2 to the newest Gamestation10 and want to see if it is still reading your saves quickly? You have a huge check box saying performance test that Gandalf told you should do to release, otherwise YOU SHALL NOT PASS?\n\nWhatever the reason please make sure everybody knows the answer clearly as it defines greatly what to focus on and if to bring mariachis or not.\n\nHOW TO\n\n\nSounds pretty evident that way before you get there you should know pretty well how to do something, right?\n\nOnce you get into that border you should have known how to cross it, or at least if you could cross it, or had the means, the visa and the passport on your donkey. But trust me, many times we just jump and honestly have no idea how we are going to make it. Which may be a really nice motivational speech, but a huge recommendation is that you know or at least have a pretty decent idea of how you can do something.\n\nEspecially true here as we are going to need technology to automate several things, but there may not be anything that can do that automatically and may end up bringing a bunch of people to click at the same time having an excuse to bring more paisanos, instead of using automation through el software.\n\nFigure out the tools and tech you will need as soon as you start and if possible do a trial to see if it cooks.\n\nWHAT\n\nPretty important to decide what will be done in line with the initial question of why, that will bring the answers, as we will not be able to do everything: bring mariachi, several colorful puffy dresses and many piñatas. Who do you think I am? El Chapo? Who has that much money?\n\nAlso no party will be good if it has everything, even if it is a quiceañera rave wedding. Please be classy.\n\nHence decide well what scenarios will be simulated and what actions on the system will be chosen to automate. Not all of them are worthy of the effort as they may not provide enough load or answers to our test. Usually 10 to 15 business cases with no more than 10 clicks each and 3 to 5 scenarios will be enough to do this right.\n\n\nWHERE\n\nIf I had a peso for every time I have seen that there is no map for the projects and no one knows exactly how everything is connected, and I mean truly everything, I would have like 100 pesos… but still that is a lot of times!\n\nGetting somewhere you don’t know without a map is nonsense, those pirates needed the steps to that huge X. Or in those labyrinths where you need to be able to write where is the trap, the tricky intersection and on what room is your mom hiding with her chancla on her hand ready to bust you cause you smell like tequila.\n\nThe solution map detailing exactly how the information travels from one point to the other and back from there is so important because without it you will not be able to know where that little hamster is getting stuck in the maze.\n\nWHO\n\nThere are two groups that you must beware when you prepare an event. Who will help you and who will attend. First you want to know who you count with. If they don’t respond. How to deal with your cousin Pepe not bringing the Coronas for the event. You can tell on his mom to bring the chancla again. You must know ho is in charge of what and will be responsible.\n\nThen who will come, only 10 kids? Several people happy to eat your food just because Maria is getting married? Or worst. Just a bunch of horny teenagers who want to see your Clarita turn 15 excited because she is now a woman?\n\nIn real projects. You need to identify the stakeholders for the whole project. Find out their roles and liabilities as they will be needed through the project.\n\nLast you need to know who uses or is expected to use the system. So you have an idea of what to simulate. Who will be there at the same time. And who will be at a worst case high load scenario. Or the usual who comes on Fridays at the last time trying to do the last things of the week.\n\nWHEN\n\n\nWhen will the event happen is very important! You must know how much time you have. To prepare the trompo al pastor, buy the tequilas and get the people skinny to fit into very tight dresses. When to hire the mariachi, if any. Or start stuffing that piñata.\n\nAs well the times are important, often not everybody shows up at the time you mention on the invitation. You know that everybody will show up at least 2 hours after that. You should focus most on that moment rather than the actual hour on the invitation.\n\nThe same here on the project. You must know what is the time frame for the overall project. It will determine how much can you do, and how to accommodate the tasks with that time given.\n\nFinally, know the times the users use the system. So you know better how to simulate and design the user distribution, or just to simulate busy hours. Maybe just that time window of Friday afternoons that is the messy one.\n\nHOW MUCH\n\nIt is important to know this to prepare for the event. To be able to predict how much food and booze to bring. As your brother Juan eats like a Flintstone. Your cousin Pepe drinks tequila like water. Plus most or your family will be there. It is highly possible that they all will get a lot of food and booze for just 50 people. Or maybe you are inviting still 50 people, but they are all part of the fasting monks group.  Which all of them may eat and drink a quarter of what Pepe does by himself.\n\nIn the same way here. You need to get answers. Such as how much are the tasks being done. Or  how much they are expected to be done. Then you can design a scenario accordingly making sure to not to overload or under-load the tested environment.\n\nWe don’t want monks exploding drunk. Nor Juan and Pepe hungry and too sober. They are the soul of the party!\n\nFINALLY\n\nAnswer those and you will be ready to trow the best event ever for you loved ones. Or the best performance testing projects ever!\n\n\n\nVamonos!\n\nBesos! &lt;3\n\n-Señor Performo\n",
        "url": "/2017/05/07/7Questions/"
      },
    
      {
        "title": "Functionalvsperfautomation",
        "excerpt": "DIFFERENCES BETWEEN FUNCTIONAL AND PERFORMANCE TEST CASES\n\n",
        "content": "DIFFERENCES BETWEEN FUNCTIONAL AND PERFORMANCE TEST CASES\n\n\nHola amigos!\n\nVery often here and there I am thrown at projects that are about to finish functional testing, user acceptance and flavor testing. They are just getting ready to move into that “performance something testing”.\n\nAnd even more often, a questionably smart person suggests, or should I say, commands that we should use the test cases they have for functional. In order to shorten the duration of the design of the performance test. So that we can start scripting scripting ASAP. After all, they do the same thing, right?\n\nJESUCRISTO, NO!\n\nEvery automated script may be the same to management. Just like dogs, they are all dogs. But we are the ones working with those dogs. We know that their skill sets are different, making each breed adequate depending on the task at hand. Just ask my paisano, The dog whisperer. He will tell you that there are breeds that are good for certain things and some that are good for other things. Try protecting your home with my little friend the Chihuahua. He may not protect at all, but may be an awesome high pitch loud alarm when he is stepped on by accident.\n\nThe same way, functional testing cases may be like a Basset Hound. They are good for sniffing all over the place and methodical. But they are awfully slow and bulky.\n\nOn the other hand the performance test cases may be like a German Shepherd. Quick as a flash and slim for tight spots. But not so smart on decisions and a little impatient.\n\nSo here are some key differences explained in my own peculiar way.\n\nDETAILED VS STRAIGHT TO THE POINT\n\nThe purpose of automation is different for each type. That is why it should be avoided to mix them or confuse them. Both may be doing ‘almost’ the same steps, but not exactly in the same way.\n\nLike with the dogs, the Basset Hound is like an airport drug and bomb detection dog. This chico will smell all over the luggage area to locate where suspicious substances may be. I mean really really everywhere. He will be sniffing all over every little corner, even several times on the same spot. Where on the other hand, the German Shepherd will just blaze through the area to grab the suspicious item and take it to safety. Or maybe even to save you, pulling you out of a fire in the same luggage area. Same process and area, different approach.\n\nOn the real deal a functional test case must make sure everything is clicked and un-clicked. It will be making sure no error is hiding on any corner or text field. By typing different combinations it will make sure the business rules work. Where performance cares little about validation. It should already have everything validated and working. It just wants to hit “Save” rapido! Filling just required fields, with the shortest and fastest possible data typing, to be as simple as possible.\n\n##\n\nFRONT VS BACK\n\nBoth automated scripts will work on separated levels, chasing each their life purpose. To find or to fetch.\n\nYou will never see a rescue dog. Unless you are the unlucky person to be on an emergency. The one that has to be rescued. On the other hand, you often see that cute puppy smelling your ass making sure you don’t have any coke. Again this is because the Basset has to check everywhere, especially where people is. And the Shepherd may jump over the roof. Then go to the basement or go around every possible obstacle (you may be one, standing there). Just to save the person with problemos or to remove that bomb.\n\nIn the same way, functional scripts will deal mostly on the client or the front end. There you may even be able to see them working live. They will click here and there. But the performance ones will go behind. They don’t care about the client computer. They just want to go and fetch the message that the server replied to their requests.\n\nREUSE VS AVOID CROWDS\n\nThe main goal of automating is also entirely different from one to the other. They were created to fulfill different purposes.\n\nYour cute Basset will be there years and years. Will be getting used to smell and search several times. Just needs training here and there, on the rare occasion new drugs or explosives appear. Maybe even if you build a new terminal. Here the rescuer Shepherds are specialized on that mission and that is it. Many times they retire after one or two rescues and they will rarely repeat it more. Small changes may really confuse them.\n\nThe same way functional automation was build to easily test again and again. The solution can be used with the same billion patterns. Helps the poor tester to not to loose their minds repeating the same task so many times on every fix or release. On the other hand, performance automation was created to avoid having a room full of people. All of them counting to 3 and then clicking at the same time as fast as possible to generate load. Imagine that you have to test 10,000 people using the software and you have no automation. Mi madre!\n\nUNO VS MANY\n\nThe way to handle data is very different as well. To handle it, to prepare it and to generate it will be very different, because the different ways each type of automation uses it.\n\nWhen the Basset is smelling all over the place one person at a time, you have only one, tops two at a time, smelling one person and done, next! Where the Shepherds may be many entering into the emergency many at the same time. You don’t want them fighting to save the same person, before they all go to the next person. Or going back into the luggage area. Just to find that there is no one else to save. He will be trapped. Unable to help anyone. Poor Pup!\n\nIn the same way a functional script may need data for every possible combination that it will be testing, but it will do it only once, maybe twice, but testing every possible combination. Where performance scripts will not only require the same record several times because they will repeat a lot, but different records that each virtual user can access for itself, as we don’t want them fighting to work with the same given parameter.\n\nMANY VS FEW\n\nGiven the nature of each testing phase, there should be many functional test cases and few performance test cases.\n\nOur sniffy buddy will repeat the same area as different planes land, repeating different combinations for each or even different actions, where the search will not be the same if the luggage area has a flight coming from Colombia, from one that comes from Vatican City, maybe those cardinals are be bringing strong ashes! Where the Shepherd goes through the luggage area only in one way, in, out, done! But several times doing exactly the same steps, at the same time.\n\nFunctional test cases may have several different flows for the same business process, functions, multiple, negative, positive and many other on the same business process, making it difficult to pick the one that may be good for performance (tip, none is). Where a performance test case just has one, that optimal route that gets the enchilada with the least clicks.\n\nFINALLY\n\nPor favor! Don’t let anyone bully you into using functional test cases to create performance test scripts. Or if you are on the other side, don’t be that manager who tries to use functional for performance.\n\nIt may be seen as smart savings. But this approach will be a huge waste of time and resources (money money!). You might not end up with a test script that fulfills the need loading the system in a wrong or useless way. It would be like testing with the squeaky Chihuahua.\n\n\n\nDo good, perform well and be feliz!\n\nBesos! &lt;3\n\n-Señor Performo\n",
        "url": "/2017/05/18/FunctionalVsPerfAutomation/"
      },
    
      {
        "title": "Reason2automateperf",
        "excerpt": "THE REASON FOR PERFORMANCE AUTOMATION\n\n\n",
        "content": "THE REASON FOR PERFORMANCE AUTOMATION\n\n\n\nWhile trying to write about a lot of topics around performance testing I found out that it may be wise to start talking about this deep question.\n\nWhat is this “something something performance automation something” actually​? What is it for? But above all, what are tacos? Food over a tortilla, or a tortilla holding food?\n\nI have seen a misunderstanding around this “something something performance something” everywhere. Somehow many people understands that the life purpose of this performance thing is to act as a timer for actions. Just a chronometer. Which actually is part of the outputs of the performance testing process. But I mean JUST a part of the whoooole process. Not the ultimate goal for the automation.\n\nAnd I blame this a little on people having been around a little bit too much involved with functional testing. Maybe just because functional happens first. Maybe because the planets are not aligned. Maybe because many of the outputs on a performance test are times. Who knows…\n\nTo make it easier to understand I will tell you a little story.\n\nTHE EVOLUTION OF PERFORMANCE\n\nIn the beginning somehow man was created (because of polemics I will not get into who did it, everybody knows it was Jesucristo), and for a while this was good. Then man just did stuff by himself and not much else was happening.\n\nThen man created the local computer. It had software on it. You could only run your stuff there and for a while this was good. Only you were using it. To measure it’s response time you could just click on it and see how it was doing. To time it just had to count seconds, check your logs or get a stopwatch to see how bad was that old CPU.\n\nThen the networked computer was created. The software on it still ran there but it started to grab little things called shared resources. It was now just a few people using this resource. Now few used that central resource. The central location required some more horsepower and to check how it was doing you could ask your coworker and/or geeky friend to help stressing it.\n\nThen the internet was created. This central location was still more or less a repository. Having there your mail, static webpages, dirty pictures and other things that you’d access with specialized programs. A few more had access to it. Testing these central computers was a little bit harder but still doable with some people at the same time.\n\n\n\nA PROBLEM ARISES\n\nNow cloud computing was created with programs running on those cloud computers instead of yours. Today they are better known as apps. These are accessed by everyone around the globe! They do it from their laptops. From their phones! Even from their freaking fridges loco! And to push that much as a global load of clicks is almost impossible just with a bunch of your friends or employees. Even putting together every family member you may have out there.\n\nYou can put a building full of people clicking at the same time. And you wouldn’t be able to load a google test server by a fraction of what it gets in a regular day.\n\nSo the main deal of automation in performance load tests is…\n\nNOT TO HAVE LOTS OF PEOPLE CLICKING\n\nIt is as simple as that. The ultimate life purpose. You automate because having rooms full of people generating load or liking the same thing at the same time is mucho. You can just create a little program that clicks that for you and then you can clone it.\n\nGenerate the almighty load. It all narrows down to it.\n\nWhen you have processes that you know will happen a lot in your system you create the automated script which mindlessly repeats the steps as much as you want to. Pretty much like the people you had clicking a lot. Then you can go evil scientist and clone the scripts. Coming them inside of a computer into tenths, hundreds and some may even hold thousands. All of that power in this tiny computer.\n\nNo more rooms full of people who need lots of space. People that needs food. People that sweat. People that may click something inadvertently. People that you cant cramp together into small spaces like if you were playing Tetris. And with computers you can! I mean, play Tetris, literally and the game itself.\n\nThis little computer will save you bucks by automating the steps, instead of needing all those people. At the same time, it may be able to pull some timers here and there on some or all of the clicks. Finding out how everything is doing while the system is getting all those gazillion clicks at the same time.\n\nBut a very importante thing I am trying to point out here is.\n\nPERFORMANCE AUTOMATION IS NOT (JUST) A STOPWATCH\n\nI hope it was clear why the main purpose of automation on performance is to generate load. A byproduct, or a trip you can hitchhike in that donkey that is already going where you are, is that while you are generating load, you can time those click responses.\n\nBut please don’t automate just to time. Well, unless you have money like el Chapo to throw at the scripters and while they are on it, to put avocado on it. Yummy delicious and expensive avocado!\n\nWith this I am not saying it is wrong to use performance automation just to time some things. There may be times where it is truly the only way. But be wise. You may be wasting your time, tacos and money.\n\nI assure you, there are many other ways you could time this instead of spending a day or two, paying a consultant per hour. Pricey!\n\nBUT WHAT IF I WANT TO SEE THOSE TIMERS ANYWAY?\n\nIf you are still curious of how slow an obscure process gets when there is a lot of load elsewhere, there are many possibilities you could try. Instead of just automating it all. Here I will give you some ideas.\n\nOne is to actually ask someone to click on that process while the load test is happening, and just… see it and time it. Which may sound counter intuitive after all my rambling about saving through automation. But as mentioned automation applies to a process that is used a lot by many people. On this case you could ask cousin Pepe to go and click. In the end he knows the system. He can click and measure time on what is needed quick and easy. But most important here, he is already in the payroll. I bet you do not pay him at all what you’d pay for the scripter.\n\nAnother pretty easy thing to do is to instrument somehow the time measurements. Many systems measure them and generate logs just out of the box.\n\nInstrumentation of processes is a whole post topic by itself. But as a quick definition, you just put timers inside of your application through many ways. This really helps towards just timing stuff!\n\nOnce instrumented, you would still need Pepe to click on it. Or just time it while the UATs or functional tests are happening to get a timing. The point here is to trigger it adequately. If it is only once or twice… Easy for Pepe.\n\nAnd again, being the most expensive, three other way is to automate and time the process through a script. One that takes longer to create, it is harder to maintain and is more picky for changes. Compared to Pepe of course.\n\nYOU ARE MORE INTELIGENTE NOW!\n\nSo now you know it. Use performance automation when you need to generate clicks by boat loads! Arriba and abajo mucho mucho!\n\nIf you are trying to gather other things like just a response time, I would suggest you other alternatives.\n\nWe will explore those other ways on further posts, but for now. Vamonos!\n\nBesos &lt;3\n\nSeñor Performo\n",
        "url": "/2017/05/30/Reason2AutomatePerf/"
      },
    
      {
        "title": "Testcases4dummies",
        "excerpt": "THE IMPORTANCE OF TEST CASES FOR DUMMIES\n\n\n",
        "content": "THE IMPORTANCE OF TEST CASES FOR DUMMIES\n\n\n\nThis topic goes in honor of a friend of mine who reminded me that it was necessary to talk about the importance of test cases quality. To be shared among the testing community. Here I am implying the whole testing community because this is importante not only for performance testing. I believe it is beneficial for all  of the testing practices.\n\nTo start let me tell you a story,  and it starts with the screen getting the image blurred while we hear harp sounds and the old image starts to appear. Traveling into the past…\n\nSTORY TIME\n\nOnce upon a time, a brave consultant was arriving at a client’s office. Happy and eager on the first day for that project. He was supposed to test an SAP GUI environment, which was his specialty here and there… or something Performance. He was conducted to a meeting room to meet the manager and kickoff the project.\n\nAfter the proper introductions were made, the manager starts to try to leave the meeting room. While just mumbling something like: “Thank you very much I look forward seeing some scripts completed soon. I guess you may even have one finished by end of day today!”.  To which the consultant was right away speechless and with an undeniable concerned expression.\n\nThe manager, noticing his unsettling facial expression stopped his escape stride and asked “What’s up?”.\n\nBarely recovering his breath, the poor consultant just managed to spit some babbling “W… Well, I need you to give me some time with the users or some expert user first. So that I can create the test cases… And to find out how to use and then test your SAP system”.\n\nThe client almost lost it. Went all bananas while his body was agitating like a chihuahua that just had a red bull. He said almost shouting “I thought you had some experience testing SAP! I was told that I would get an expert! Especially after what I am paying here! I can’t believe this! How is this possible that you need me to tell you how to use SAP???”. This left again a peculiar expression on the consul__tant’s face. \n\n\n\nAfter a few seconds the consultant dragged all the air he could get on his lungs and all the wits he could get on his cojones, and started a speech…\n\nI will stop the story here for a bit to not to ruin the ending and give some learning before the climax comes.\n\nCOMMON PROBLEMS WITH TEST CASES\n\nThere is a problem that often arises with test cases. It is that they are created from functional cases, which is wrong and bad and badong for several reasons. I rambled about those already on an earlier post. But aside of the explanations of why this should not be, another important piece is the reason for this to happen.  And the answer is that this happens often because a “wise” manager thinks it is easier that way… Maybe cheaper… Or faster… Hopefully all of the above. Which we already know is all of the above wrong.\n\nIn order to not to fall into this mistake, the best option is always to get access to the expert on the business process and spend from 30 to 60 minutes documenting the steps to create the almighty test case. Don’t try to save on this vital task, you could end up training a doberman to act like a cat. Maybe even worse like a Chihuahua.\n\nThere is another great problem that often happens by doing this. Not only to performance testers but to all testers that depend on test cases to do their work.\n\nPicture this. Somehow you receive a test case to work. And it reads something like this:\n\n\n  Process a purchase order.\n  With the Order number create a delivery process.\n  Absquatulate the cacoethes transcender and ionize a flaring ergometer to generate a fankleID.\n  Confirm the shipment on the galligaskination transaction.\n  Save.\n\n\nI am sure your have been there. With the familiar expression…\n\n\n\nKEEP IT CLEAR AND SIMPLE STUPID – KICASS!\n\nThis test case was written for an expert on SAP. Which includes… all that… whatever all of those steps meant. Of course requires someone that not only knows what the heck a cacoethes transcender is, but a lot of the customization done to the purchase order transaction. Not to mention someone that knows what the F with the custom galligaskination transaction. And no it has nothing to do with Zach Galifianakis.\n\nWouldn’t it be better that it was written something like this?\n\n\n  Open SAP Logon and access the XXX environment.\n  Type the user and password and press enter.\n  On the top left of the screen click on the arrow to type the transaction ‘VA01’ and press enter.\n  Type ‘001’ on the Org ID field, ‘AAA’ on the company field.\n  etc.\n\n\nI hope you see the point here. A test case has to be very detailed. This means that it has to be written for dummies. Describing steps that your grandma can understand and follow (who barely knows how to use Facebook, thank god). This is straight forward for evident reasons and brings several advantages.\n\nADVANTAGES\n\nOne of them is that there will be no confusions. You have clear repeatable steps. Every time that someone reads them. Regardless of who is the person testing. Because everybody pastes right clicking and selecting paste, there is no other way.\n\nAnother one is that the person testing or automating will not need to know anything about the industry. Imagine you were testing some NASA’s systems. You would actually need a rocket scientist tester! (Dinero dinero!)\n\nAnd last, you wont need someone who needs to be an expert on the platform, or in the customization you may have done to the system. Their enterprise solutions are tweaked often. They buy them, and change them to be useful to their particular needs.\n\nHaving these clear test cases, your tester just needs to know how to validate the steps or  know how to automate on a specific platform. Without requiring knowledge of the customization you may have made. Neither to have any knowledge on the business.\n\nFor this reason, imagine how expensive it will be (not to mention hard to find) to get a tester expert on SAP automation, expert on NASA’s customization, mind reader to know what customization you may have different  from his previous client. And the cherry on the cake. A freaking rocket scientist!!!\n\nEND OF THE TALE\n\nBack to the story.\n\nWhen the poor consultant recovered his breath from the client’s ramble he just quietly replied.\n\n“I am sorry but I absolutely need you to help me to find out and document the steps for the tests. To be honest I am not an SAP expert. I actually don’t think anyone can call himself a 100% SAP expert.\n\n“I am an SAP performance test expert. One of the best ones you will find BTW. I know really well how to stress that bastard!\n\n“But I actually don’t know very well how to use it. I have been indeed on several projects with several clients using SAP, but they all used it differently. You sell cereal. My last client sold toys. The one before sold hamburgers. And the ones before: medical instruments, insurance, video games, etc. And no one used the system the same way. They have different products. Hence different logistics.\n\n“They even stress different areas of the system on a daily basis. Some even lack complete modules.\n\n“Yes you are paying so  much because I am a testing expert. Imagine how expensive it would be an everything expert. Most of the time I don’t even know what are the steps doing. Most probably I will have no idea of what your steps do, after I am done here .\n\n“But there is something I can totally assure you. The steps are going to be automated and executed flawlessly. At a level that the very best ones in the industry do it\n\n“I need you to show me how you use your system in your particular way, or you could go out and look for that omnipotent expert. Good luck with that.\n\nThe consultant dropped the mic and after a few moments of silence the client slowly started clapping and stood up. Kept clapping louder and faster until it hurt. Right after, the client almost hugged the consultant. The client directed him with fanfare to the wing where the expert users were working.\n\n\n\nAnd they lived happily ever after.\n\nCLOSING\n\nOf course it did not finish like that. The client had a slightly pissed off expression as he had to swallow his words. The client said quietly: “I see now. I will try to get you some face time with the experts users”. Using the joyful tone of someone who just lost a $100 USD bet. He just learned a tough lesson in a hard way.\n\nWe have now learned this as well. Some of the huge advantages that come having detailed test cases. In a way, that didn’t hurt, I hope. Some of these advantages are clearing the dependencies of expertise on other areas different than testing. Which decreases the cost of the testers hourly rate considerably.\n\nNext advantage. The steps are repeated exactly the same way every time. All through testing cycles.\n\nFirst and foremost, there are several other advantages on having test cases for dummies. However, that is a whole new talk for another day. Ultimately I think that is enough for today amigos. Lets go and stay feliz! Vamonos!\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/06/05/TestCases4Dummies/"
      },
    
      {
        "title": "Howscriptswork",
        "excerpt": "PERFORMANCE TEST SCRIPT – HOW DOES IT REALLY WORK?\n\n\n",
        "content": "PERFORMANCE TEST SCRIPT – HOW DOES IT REALLY WORK?\n\n\n\nI have noticed several times that many people do not know how does the performance test automation work. Not only clients, but even some testers seem to be slightly confused about the true ways of the performance test script.\n\nAgain I blame a little these misconceptions on functional test automation. There are several differences among these, some I have already rambled about on a previous post.\n\nClients, managers and even some testers alike have gotten used to see the execution of the functional automated script. They love to see those buttons to be magically pressed on their app, giving them that warm sensation of something being done. But performance test scripts do not work by actually clicking. It would be a waste.\n\nI am going to use one cool description for performance automation to show you how it works.\n\nPERFORMANCE TEST AUTOMATION IS LIKE HACKING\n\nSay whaaaaa? Are you surprised? Don’t be! This is so true that you would be shocked how similar it is that actually it could be the same. At times it is.\n\nThere is a term called DDoS (stands for Distributed Denial of Service) that refers to a technique some hackers use to make web sites and apps slow or even unresponsive. They do this by sending a big amount of requests to the attacked site from many different computers at the same time to bring it down.\n\nIf this doesn’t sound familiar enough, on the previous sentence change requests for clicks. Attacked for tested. Finally change computers for Load generators. Now read this:\n\nThey do this by sending a big amount of CLICKS to the TESTED site from many LOAD GENERATORS at the same time to CHECK PERFORMANCE. – Mind blown!\n\nIn essence this is what load testing is. Send many requests to the main server to see how it handles that many. Even at times you may be interested into checking if you can bring it down like the hacker!\n\nTHEY JUST DWELL ON THE BACK END\n\nMost of the performance test scripts do not actually click the button. Some do, but those are extreme cases, more on that later.\n\nClicking buttons is really expensive in terms of hardware. To have a button created for every virtual user is a lot. We usually don’t care about them (the front end). It is easier to just send the message that the button generates.\n\nImagine a real life example. A fast food kitchen works a lot like an application server. Where you have a lot of cashiers taking orders (clicking the buttons on the app). They type your order sending it to the kitchen through service tickets that appear in a tiny printer inside the kitchen. Then the cook prepares it and returns the order on the window so that the cashier can pick it up.\n\nSo if you want to load test the cook, what would it be easier? To get a lot of ordering machines? Or to just plug one computer to the printer so it sends similar tickets to the kitchen?\n\nThis way, as long as you know how to make the printer print what you want (in a way that the cook recognizes) you can send a lot with just one computer! And you don’t even need a fancy computer! Nowadays even many cellphones can print stuff. Making it super cheap.\n\nSOMETIMES YOU HAVE TO GO FRONT END\n\nI said previously that we would go to the back end most of the times. But some times this is going to be impossible as the message will be impossible to be created.\n\nMany vendors create their software in a way that only their mothers may be able to recognize them. And even some times they wont be able to tell. Or just with encrypted messages, same story.\n\nImagine again the example of the printer in the kitchen. There are those hellish peripherals that will only work with what the vendor made them. Good luck if you don’t have the printer driver. Or a special cable. Or a software to call it. All closed and impossible to test.\n\nHere the only way is to get many terminals and automate robot arms to click doing the kitchen orders. Sorry, no awesome printing 1000 orders from your cellphone.\n\nCREATING THE MESSAGE IS LIKE SPYING\n\nThere is another big component. It is to create a message that can be recognized by the server. Just like faking that you are someone else. Multiple someone elses. This is very similar to other hacking techniques. One of these is called a “man in the middle“.\n\nA man in the middle attack basically is someone or something tapping the wire where you are having a conversation. Listening and paying close attention to the conversation. Pretty much like you used to do with old landlines. When someone was talking on the phone and you quietly lifted the speaker of another phone to hear. You little vouyerist!\n\nThis way you can take notes and record those conversations. Imagine a foreign restaurant you want to prank. You would tap into the line and listen people making orders:\n\n“Hola, llama a taco pelota le atiende Lupe. Quien habla? – Hola Lupe soy Pepe. Quiero 3 tortas. Gracias”.\n\nWe will spy on some conversations the same way so that we can learn how to talk to this server.\n\n“Hola, llama a taco pelota le atiende Francisco. Quien habla? – Hola Francisco soy Juan. Quiero 1 pizza. Gracias”.\n\nNow that we have some we need to create a message.\n\nFORGING REQUESTS\n\nPerformance test scripts will just replicate the message that creates the order. They wont actually pick up a phone. Neither click the dial keys. Not even a person will speak. We will have a recorded message.\n\nBut for this to work, we need to identify the parts that change. We will structure messages identifying what changes. We may not even know the language they are speaking but we notice the differences.\n\n“Hola, habla a taco pelota le atiende CHANGE. Quien Habla? -Hola CHANGE soy CHANGE. Quiero CHANGE. Gracias”.\n\nWe have now a working message. Knowing what to change and insert on them is a whole topic on itself. But once we know what to change and make sense, we will be able to create as many combinations as possible. Have an automatic player and call orders nonstop without much trouble.\n\nThis way the server will think we are someone else and take our order. Even if we don’t know Spanish we can make orders that the server will recognize.\n\nThese messages are often very complicated to forge. They may be on Chinese, alien or hieroglyphs. The challenge is to assemble a message that the other side will recognize and do as we request without hanging on us. Forbidden access! Oh no!\n\nFINALLY\n\nSo now you know performance automation is not about recording pretty clicks and seeing them on the screen happening (if you are lucky). Neither timing those clicks. It is about copying the messages that the clicks do. Forging similar messages and just directly sending them in a cheap way.\n\nHowever there are other ways. But what I just described to you is the most optimal (and how most performance tools work). If you want to see how the cook manages the kitchen at lunch hour when everybody wants their tacos, follow these tips.\n\nLets go and create some load. I mean, order lots of tacos.\n\nVAMONOS!\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/06/12/HowScriptsWork/"
      },
    
      {
        "title": "Notesteverythin",
        "excerpt": "DON’T TEST EVERYTHING ON A PERFORMANCE TEST\n\n\n",
        "content": "DON’T TEST EVERYTHING ON A PERFORMANCE TEST\n\n\n\nHave you ever arrived to a performance test project where the client wants to load test everything? Where you are told that you should automate a gazillion business processes? Have you got upset from that nonsense? Especially when you are asked to automate something silly like a batch process call?\n\nIf you get requests like this. If you did not get upset by this nonsense. This read may be for you.\n\nThis is wrong in so many levels that I will start little by little, and maybe post by post.\n\nBut lets get something clear first. We already talked about some differences in between functional and performance. Where the business processes should not be followed the same way. In a similar way, the amount of business processes are not the same either. Functional should test everything. Performance should not.\n\nPERFORMANCE AUTOMATION IS COMPLEX\n\nAs we already discussed earlier here, performance automation works on a different layer than functional automation. Functional automation just reproduces clicks. Really doing them.  While performance automation forges the messages that those clicks create.\n\nIt is just way more complicated and hence unstable. But most important of all is that it is way more expensive to automate for performance. Dinero dinero!\n\nYou could test everything if you are as rich as El Chapo. Otherwise you may want to focus the effort (and money) where it will be more effective. And maybe you are as rich but want to be smart on how you use your resources.\n\nYou may be questioning yourself now. How do I know what to include in my scope to be safe and not spend like there’s no tomorrow?\n\nHere are some guidelines.\n\nPERFORMANCE TEST AUTOMATION SIMULATES MULTI-CLICKS\n\nI know. You already know this. Just because you read it in a previous post. You are an expert on this now. But there is another catch to this.\n\nIf performance automation was created to simulate a process that is clicked a boat load of times. By a lot of people clicking the same thing. Maybe even at the same time. Many times. Then, why are you asked to automate a process that is executed only by one person at a time? Even worse. This person clicks it rarely. Not even once a day!\n\nDo you see the issue here?\n\nNo? Imagine this.  You are asked to automate a business process. The process sends your tax declaration to the IRS. You tried so hard to push back this from the scope. The argument is that the process is executed only one time once a year. But the client said that it MUST be included as it is a CRITICAL process. Muy importante!\n\nLOW HITTERS ARE CHEAPER MANUALLY\n\nThe client wants to test everything. You have some processes that are really important but happen with a low frequency.\n\nA process that will get this low load usually receives it while the team is doing other tests. Tests such as unit, functional, integration and even UAT. There was already a plethora of chances to detect any slowness by now. Before you do and actual performance test. Don’t you think?\n\nThere should be no need to test it again for response times. The response times should be available by now from the earlier tests. But come on, that doesn’t happen in real life. Not that often.\n\nNow we are in the load test phase and must include this process and time it. Let’s consider these two options.\n\nOPT1: AUTOMATING\n\nUsually a performance automation takes from 4 to 16 hours to have a finished test script that is reliable. We will average the time it takes at 10 hours. It will will take a consultant scripter about 10 hours to automate it.\n\nOn the market nowadays I believe a performance scripter consultant costs $50 dollars per hour on the cheapest side.\n\n\n\nThe script will cost the client $500 dollars. Just for the script. No travel included. Neither the consultant’s presence during the execution. The script will need some baby sitting just in case. Dont forget it.\n\nAlso, I will not include the cost of the creation of the test case of such business process. Remember here we mentioned why you should use one specifically for a performance test.\n\nBut on the cheapest side we will close it at $500. Sweet moolah!\n\nOPT2: PEPE CAN DO IT\n\nAnother option is to ask Pepe to do it. He is already a user on the system. He has the knowledge on how to execute the process. And the best attribute he has is: he is already on the payroll!\n\nThis translates into Pepe costing way less than a consultant. Where saying “way less” feels like it is falling short. In the rare case that Pepe earns a six figure salary, he would cost about $45 dollars per hour.\n\nBeing realistic Pepe must be getting about $20 to $30 per hour. But let’s go with $45. On this example Pepe is really special and earns top money.\n\nNow, how long will it take him?\n\nWhile you are doing your load test, bring Pepe and ask him to trigger the process. Which I bet you will not take him more than 30 minutes. But let’s assume it takes him one hour. Also being extra OCD we ask him to make it twice.\n\n2 hours x $45 dollars = $90 dollars.\n\nJust slightly above 5 times more expensive. Taking into account that we asked Pepe to do it. Which makes it slightly ridiculous to put someone with a 6 figure salary.\n\nNevertheless I guess you get the point.\n\nBUT WHAT IF I WANT TO MEASURE RESPONSE TIME?\n\nMany managers have asked this again and again. Feeling uneasy, almost insecure. They want to see that response time recorded. They are oblivious to the fact that there are other ways to measure that response time.\n\nThe first one is automatic trace.\n\nMost solutions already trace those hyper important processes automatically.  I would worry if they did not track this response times. I would question the quality of whoever developed it. Home made or made by a third party, that is not cool. Malo, muy malo.\n\nGather those from the solution. But if the solution is not a good one. If there is no record of the time the processes take, there are more choices.\n\n\n\nAnother one is a stopwatch.\n\nYou know that awesome invention. There are cool mechanic ones. Others are modern and digital. And legend says some smart phones can do it. There are amazing options that may cost about $5 bucks. Thank you cheap Chinese technology.\n\nJust ask Pepe to use this magic device. To type it somewhere when he is doing the  business process. And listo! Add $5 dollars to the total cost of this. Pfffff.\n\nCONCLUSION FOR MANAGERS\n\nYou saved about $400 just for that business process. Just think about the other 50 processes you wanted to include and automate. Do the math on that requested nonsense.\n\nYou just saved about $20’000 bucks (50 processes x $400 dollars). Just by being smart on the way you performance test on a load test. Not to mention all the time that scripting would have consumed. And proper test case creation for each.\n\nI really don’t want to make it just about the money. There are many other reasons to not to automate test everything. I will go into the other reasons on a follow up post.\n\nBut the money will be a good starting point to make a manager or leader understand. You would be using their lingo. Taco’bout dinero dinero!\n\n\n\nMore will follow on the reasons to not to automate test everything.\n\nI will add a link here once the follow up post is written. But for now… VAMONOS!\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/06/19/NoTestEverythin/"
      },
    
      {
        "title": "Phasesawesomeperf1",
        "excerpt": "THE PHASES TO AN AWESOME PERFORMANCE TEST\n\n\n",
        "content": "THE PHASES TO AN AWESOME PERFORMANCE TEST\n\n\n\nA performance load test project requires to be done in phases to be done right. This phases could be thought as levels in a video game. These phases are known by different names. But in essence they refer to the same things. Ketchup or Catsup, the same bloody thing.\n\nThese levels in your project ensure that you have a great project done. It drives me loco when I arrive at a client and they ask right away when am I going to start scripting. Maybe that same day?\n\nScripting is not the core of the project. It is just a tool for the goal of a load test project. But the goal is to request a lot to the server and gather metrics about those requests. Validating the quality of those responses ensures that you have a product that performs well.\n\nA STORY FROM THE PAST\n\nThe client often misunderstands this. Makes me think of my old man, the true Señor performo… senior. He did some construction projects around our house when I was a kid. But the problem was that he did start construction right away, without much preparation. He just told a constructor, build me a room here, with a bathroom there and windows on top of it.\n\nThat extra room required constant fixes through most of my childhood and my teens. Water leaked through walls. Sharp corners on walls caused injuries. Even the freaking bathroom had no door! Thankfully nowadays it has one (It is made out of transparent crystal thou).\n\nI hate to use this term. But sadly you could say that the project was done the “Mexican way”. No planning, just doing, and hoping to fix it later with duct tape.\n\nLet’s try to clean this “Mexican way” stigma. I will show you now the steps that your load test projects should have. Please, once you understand them, try your best to not to overlap them. I promise you that by following this, your project will be awesome!\n\nPHASE 1: FIGURE THINGS OUT\n\nThis is the starting point. This phase may be known as DISCOVERY, ANALYSIS, FINDINGS, REQUIREMENTS, etc. Therefore, this is the phase where we will discover the details of the project.\n\nWe may not know the nature of the tested application, even as we are expert testers on that technology. We will have to answer a bunch of questions. These questions were detailed earlier. It is really super important to have an answer for them. Trust me, I am a consultant. (wink wink)\n\nLets go through those questions quickly.\n\nWhy do we need the project?\n\nHow are we going to do it?\n\nWhat are we going to test exactly (business processes)?\n\nWho uses the system and who is in charge of stuff?\n\nHow much is it used?\n\nWhen are the dates for the project and tests?\n\nFinally, where is everything (the topology map)?\n\nSimilar to what i mentioned with Señor Performo senior. This would be like a terrain analysis. You will find out if you need permissions. Check for existing plumbing so you know where not to dig. Verify the humidity of the land. And a freaking analysis of why do bathrooms require doors!\n\nPHASE 2: THINKING AND PLANNING\n\nYou have the required information to put together an actual plan now. This phase receives different names, like DESIGN, PLAN, ARCHITECT and many others.\n\nDon’t be confused if some organizations fuse this phase with the initial phase. That is OK as long as whatever you do, you do not skip the important tasks.\n\nHere you will create a detailed set of steps that will take you to the goal. During this phase you will produce two of the greatest assets of your project. The ‘Test cases’ document and the almighty ‘Test Plan’.\n\nFor the first one, you need to select and document the test cases that you will use to automate the load generation during this project.\n\n\n\nHowever, you will not test all of the business processes that the system is capable of. We already ranted about that here. Here you will filter the worthy ones and document them. Than you will proceed to create the almighty test cases optimized for performance testing. Jesus! Please, not from preexisting functional cases, like I mentioned earlier.\n\nAfter you have a set of awesome test cases, we will create another holy document. The almighty test plan (angel chants in the background).\n\nThis sacred document will be the backbone of the tasks for the project. At times, it will be as detailed and beefy as 50 pages. Actually, I have done some that are longer than that. The test plan could also be placed on an short(ish) email. Just please make sure to include all the important information. This will be like your guide map to an amusement park. Not to mention, a very important CYA.\n\nThe equivalent on Performo senior’s construction example is a blueprint. I know, this sounds like nonsense. Who in their right mind would construct a building or a house without a blueprint at all. You need at least a simple one with stick figures clear enough. I dare you to live in a house or a building constructed with no blueprints. Nothing else but just the whims of the constructors.\n\nPHASE 3: PREPARING ALL TO TEST\n\nThis phase is NOT the most important part of a performance project.\n\nThink about this phase as the part where you gather all your equipment. Prepare the items you will need. Plug all your tools. You may do this step several times each time you want to do a project or on each iteration.\n\nWe have discussed already what is the true need of an automated scripts. They should not be immortal and reusable. They are not at all. Most of the time they are incredibly fragile. That is why you need simple, quick and performance oriented test cases. To script them again in the blink of an eye if needed.\n\nAs well, here we will create and prepare the scenarios. The business process orchestration that will be run during the test execution. In the end we will configure the monitors if the solution allows it.\n\nThink of this as buying the tools and preparing the cement mix. Here we won’t do the construction per se. Instead it will be like bringing all the sand. Prepare and connect the tools. To have ready every material so that we can construct it all at once. Following the blueprint needs. Unlike my dad’s project, we went every weekend for another bag of cement. Other times for paint. And on those trips we figured we needed a new tool that week. But still no bathroom door.\n\nTO BE CONTINUED…\n\nI want to keep these posts under sizes that will not tire you amigos.\n\nBut this part of the topic is long and will require more details. As even this part I tried to keep things short, this is a huge monster.\n\nBut the only way to eat an elephant is… One bite at a time.\n\nI will leave you with a cliffhanger and continue the post on the next post. But to increase the suspense, next show we will discuss of the actual state of that bathroom door! But for now… Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/06/26/PhasesAwesomePerf1/"
      },
    
      {
        "title": "Phases2",
        "excerpt": "THE PHASES TO AN AWESOME PERFORMANCE TEST 2\n\n\n",
        "content": "THE PHASES TO AN AWESOME PERFORMANCE TEST 2\n\n\n\nToday I will finish talking about this important topic. The phases you need to follow to assure an awesome performance load test project.\n\nIf you did not read the previous post, you can find it here.\n\nDoing a quick recap, there is a huge problem when a project does not go through those phases. I used the example of a construction. This starts right away putting bricks together. Just for the sake of building. Causing a horribly long process. This never creates a good construction.\n\nBack at home I saw these types of constructions often. I even used to live in a house that had one appended during my childhood.\n\nNow that I am an hombre. I am still finding these horrific situations. I do not see them in constructions anymore. Those situations appear on performance testing projects. Everything goes wrong on these.\n\nLets see the phases we already talked about.\n\nPHASES 1, 2 and 3\n\nThe initial phase, when you are discovering the situation. Answering the most important questions. Important answers that the tester requires to define the project. We will act like detectives. Investigating every detail needed to start thinking about the project.\n\nSecond, we will design and plan everything. Producing two of the most important tools for the project. The test cases for the selected business processes. As well as the performance test plan. Both of these are cornerstones of our project. Not the scripts who are fragile and will be unusable in a month or two.\n\nThird, the preparation process. The team will use the Test Plan together with the Test Cases. They will create tools with them. The automated business processes. Better known as test scripts. as well as the orchestrations of those scripts executions. Better known as test scenarios.\n\nEach phase creates a bunch of outputs. The next phase will use the output. We have been diligent with every step. Now we can move on to the next level.\n\nPHASE 4: ACTION!\n\nThis phase has several names as well. This phase has many names elsewhere. Such as ACTION, EXECUTE, RUN, TEST, etc. This is the moment when everything actually happens.\n\nWe will use everything that we have prepared so far. The scripts are ready completely flawless. Done with the best steps described on the test cases. On the other hand, we have the scenarios ready. All created according with the specifications described on the Test plan. Last, we have the monitors ready. Someone else may manage them. That is cool, too.\n\nNow we will proceed to prepare for the fireworks. Make sure to call everybody to the show. At the minimum, you must invite everyone interested in the project. It could be someone interesting for the project as well. Everybody must be there. Or at least the important people must be aware of that we are doing.\n\nWe will start everything to generate the metrics on our test. Here is where all what we have worked for starts to produce something. Be aware if something breaks and show it to the audience. Gather the information produced and store it for the next level.\n\nFollowing the example of the construction has an easy analogy. Here is where you bring everybody. Use what you have prepared so far, and put it together to construct. Put the bricks you brought. Plaster them with the cement you mixed. Dig the holes with the tools you have. The process will be fast. Completing the project in an efficient way. You follow the plan and the blueprints. Everything is awesome!\n\nPHASE 5: SHOWOFF\n\nThe test is now complete. You are almost ready to call it a day. The final phase receives different names on different companies. ANALYSIS, REPORT, DELIVER, VALIDATION, etc.\n\nOn this final step we can count the task as done. We will proceed to pack it up. Checking all what we found during the execution. We will put it together on a nice way because we got a boat load of data. This will be an easy way to understand as it will be pretty. It must be at least a bit prettier than a bunch of piled numbers in a CSV.\n\nI recommend to put it with shiny and pretty graphs. Make things easy for anyone. Start things with the main findings. Avoid any boring stuff at the beginning. BAM! We found this!\n\nThe main findings go on top to make it interesting. My abuela must understand the language. The rest… well, few people will read the rest. Just be a good boy and place the details of the findings afterwards. You must throw a party. Present the main findings to the most important fellows. There you can deliver the document.\n\nOn the construction example we can think of this as the inauguration. Make sure to do a big public show. Cut the red tape. Show everything you built.\n\nCONCLUSION\n\nI want to make sure you understand this. Please be careful. Follow a due diligence when you are conducting projects. Not only performance testing. Any project requires to follow the steps described. Even the famous PMI suggests some phases that ring a bell incredibly. Actually I got these from their steps.\n\nYou can see it. They apply to almost any type of endeavor. You wan to do something. First you investigate about that something. Then you plan on how to do that something. Next, you prepare yourself for that something. Finally, you do that something. And  last you finish and call it a day.\n\nThink of it. Most of what you have done has these steps. And think of the times you didn’t do them. I bet hi that it did not go very well. It must have been a lucky day when you did not follow the steps and things went well.\n\nI beg you all. Be diligent. Don’t jump in just wanting to do a something something dark side. Don’t build without planning. Not without thinking first. Like my old señor… My old man.\n\nThat extra room looks better nowadays. But still, it need work done here and there. The only way would be to demolish and build again. Planned and thought.\n\nYou may have felt my trauma with the bathroom. You can relax now. It has a door now. Only thing is that it is completely transparent.\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/07/03/Phases2/"
      },
    
      {
        "title": "Script01date",
        "excerpt": "SCRIPTING 01: DATE THEM BEFORE COMMITTING\n\n\n",
        "content": "SCRIPTING 01: DATE THEM BEFORE COMMITTING\n\n\n\nOn this post, I am going to start a series of posts that will talk about date and relationships. NO! I am just kidding. They are going to be about scripting techniques. On these posts I will state some of the best practices that will help you to be the best scripter. These best practices may apply to other automation areas. But the focus for these best practices is for performance testing automation.\n\nThese recommendations will give several advantages. Some of those advantages are:\n\n\n  Faster scripting times.\n  Ensure that the amount of re work done is minimum.\n  Clean and efficient code for the scripts.\n  Ensure that the code is flawless.\n  Minimize errors happening on execution.\n\n\nThese practices have allowed me to brag zero execution errors with my clients. Well, I get zero errors from the scripts and the test. Other errors come from the tested solution. Most of the clients don’t believe me. But I have actually won bets on this!\n\nFIRST STEPS FIRST\n\nI am going to give you these recommendations in order (more or less). From the first ones, to the last ones. Some of the ones in the middle can change in order. But the ones on the ends, firsts and last ones, must be respected!\n\nThe first recommendation that I will give you must be done right after you receive the test case(s) that you will script. Here you must make sure that you receive a test case optimized for Performance. I already talked a lot about those.\n\nThis first step must be done before you open any scripting tool. You don’t need it for now. This is because the first thing that you are going to do is to just follow the steps. To get familiar with that process before you script anything.\n\nIt is a lot like the first time(s) you go out with a girl. You must come to know her a little before you start to do any serious business with her. Way before you bring her to your parents’s house.\n\nJust a note before I move on. I am an hombre (not a bad one, at least not too much). And I haven’t dated any other hombres (nothing against it, just not my thing). So the examples about dating the script is going to be a girl. I am trying to be socially correct. But I write from my own personal experience. As usual all of the stories are true stories.\n\nGO OUT ON A FIRST DATE\n\nHere you will try to hold your test case’s hand. Walk with it for the first time. See if you can go at its pace at first and make sure that it is valid.\n\nThis way you will confirm if the test case is up to date. Because they are always up to date, right? (Ha!)\n\nWrong! Often, while you are following them, they will specify some steps and you will be like WTF. “What is the button that I must press? I don’t see any button”. There you can report the test case as outdated. Ask the test lead or someone in charge of it to update it . Most probably, you don’t know how to use the system. And even if you did know, the test case should be clear and up to date. I mentioned this before.\n\n\n\nYou will have saved time detecting this first hand. You will not have even opened the scripting tool. Not even scripted a thing!\n\nIt is important to do this first. It is like the first date I mentioned. You wouldn’t bring home a blind date. What if she is mean? Or ugly? Or looks like you picked her at the corner of a sketchy neighborhood? Your mom may unleash the chancla power on you two. She will unleash it on you for sure.\n\nBecause of this, go out on your own with the girl first. You must check her to make sure she is compatible with you. Maybe she has bad breath. It could be that she doesn’t understand your jokes. She may not even like them! Or in a worst case scenario, she may not even like tacos! Dios Mio!\n\nGET FAMILIAR WITH EACH OTHER\n\nThere is a second advantage to this step in the best practice. You will get at ease with the business process. Come on, you can do it. Touch it for a bit. Before you jump into recording.\n\nExecute it manually just because. Get familiar with its flow. See where it receives data. Find the different values that you must enter. Identify the points that will be measuring response times. Understand why they are important. Report the transactions that you consider that should not be recorded. Claim to track the timers that you see that are missing and seem to be important. Tell on the ones that should not be there because they  do not have post back times.\n\nBy doing this you will decrease the number of failed attempts to record. I am sure you know what I am talking about. When I was a junior scripter I didn’t follow this recommendation. I would just open the unknown test case and the scripting tool at the same time. Then I would try to record the script right away. Just to have to start all over again several times because I missed a click. I would mess up because I was not familiar with the steps at all. There was so much time lost starting all over again several times.\n\nIt is the same with the date. First you confirm that the señorita is good. Now you have to find her perks and details. Maybe she doesn’t like olives and you like them so that will work. Maybe she likes to use heels on Sundays. This makes her taller than you. Then you will use your platform shoes on Sundays. You will also find out what types of tacos she likes. It is not a matter of if she likes tacos. She must like them, otherwise we wouldn’t have made it to this point in the dating game.\n\nBE A REAL RELATIONSHIP\n\nThere is another benefit to this best practice. You will act more natural the more you execute it. You will be more like a pro real user. Regardless of having no idea of what the steps are doing, like we mentioned before\n\nThis natural flow brings scripting advantages. Once you are scripting you will sprint through the process. The steps are going to be easier. Instead of you having to stop for hours trying to find a parameter, you will wait a realistic amount of time. This way you will record wait times that are closer to the ones that a real user would do, instead of the waiting times of someone ignorant.\n\nIf you dash like a real user, you will record real wait times. This is good if your project depends on them for accurate wait times. Now you will get pretty good ones.\n\nIn the same way, when you go often out with the señorita, you will find out her likes. You two will be normal with her. You will know right away what places she likes. Decide instantly on a restaurant to go to dinner. Instead of you two wasting time in the classic conversation that everybody knows:\n\n\n\nMe: Hey Maria where do you want to go to eat?\n\nNovia: Anywhere you want mi amor.\n\nMe: Lets go to Taco Pelota!\n\nNovia: Aye no, I don’t like it there.\n\nMe: Well then, where would you like?\n\nNovia: Anywhere you want mi amor.\n\nMe: …\n\nCONCLUSION\n\nVery well amigos. Now you know the advantages of dating your test case first. To know it before you commit to anything serious. Like opening the scripting tool and start recording. Don’t do it, if you don’t know if it is going to work between the you two.\n\nGet to know the test case like any señorita that you just met. Go out first. You must check if she is good and/or pretty. Then get to know her with all of her peculiarities. Get some practice so you get used to each other. Only then you can take her home to introduce her to your madre. I mean, so that you can record the steps in the scripting tool!\n\n\n\nWe will continue this series on the next post. For now, vamonos!\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/07/18/Script01Date/"
      },
    
      {
        "title": "Script02pairs",
        "excerpt": "SCRPTING 02: BRING THEM IN PAIRS\n\n\n",
        "content": "SCRPTING 02: BRING THEM IN PAIRS\n\n\n\nToday we will continue with the scripting series. I will tell you about the second recommended step. It is ‘record twice the same steps so you can get pairs’. The advantage here is that when you get two recordings of the same steps you will have comparisons. That will ensure you can identify everything that changes.\n\nWe want to ensure that we can identify the changes because that will ease the detection of correlations. Instead of doing just a try and error. This will give you a LASER targeting on what to correlate.\n\nAs well, here you will create a point of return. This return point will be like a video-game checkpoint. Where you will be able to return to, every time you mess up.\n\nLets see what is the process for the second step.\n\nRECORD THE DATE\n\nOn the previous step we learned that you must familiarize yourself with the test case. So, now you two should be intimate. You should know the variations of the steps according to the test case. So we can finally proceed to open the recording tool.\n\nChoose one flow pattern first. There you will choose a set of specific data. Get one of each of the parameters that are in the test case.\n\nNow go on and record the steps like a pro. Go through them like a real user would do it. Do not worry about transaction timers (for now). Neither about other things such as wait times or parameters. Just record it clean at once. Flow through the steps like water.\n\nThe only extra thing that you may do is to insert a comment or a marker. You must do this where you think a timer will go later. Maybe where you notice there is a request done to the server. But keep it short, just a little word or a comment.\n\nThis will be like tagging the cattle. Just add a quick tag here or there. Don’t do anything complicated. As mentioned just type a word and keep going until the end. Until you get your first clean recording.\n\nThat’s it. Save the script and move on. Put on it a name tag Trying to prepare to have another one of the same kind. Maybe call it Perro, or Perro_01. Once you have named it, push that little animal into his pen and move on. We will check this buddy later.\n\nGET A FEMALE TO HAVE PAIRS\n\nYou saved the previous script. Now we need a companion for it. We want them in pairs. Just that this time, we will change all of the possible different inputs.\n\nSelect a different set of data, wherever the data changes. This is really important. Make sure you select everything that can be typed different according to the test case.\n\n\n  Parameters\n  Credentials\n  Dates\n  Variable data\n\n\n\n\nOnce you have the data selected proceed to record a NEW script. You must make sure it is in a new one. Generate it completely from scratch. Please, you must be careful to not to overwrite the previous one.\n\nIn a similar way as we did with the previous one, just record it. Add few tags here and there where you consider important to identify in the code. Once you have recorded it, store it in the same pen as the previous script. Just name it with a similar name. Something like Perra or Perro_02.\n\nNow you have two of the same. The special parts of each of them will be different, just like in males and females. You will have the couple. Now we can produce puppies! (Get puppies sounds better right?)\n\nTHE PUPPIES, NOT THE PAPI’S\n\nNow we have two scripts recorded. We may have more than two if we felt kinky or with enough time. But we must have at least two. Not less.\n\nNow we will copy them. Create a copy of each and leave those originals untouched. You created those just to have them safe and play with the copies.\n\nThe advantage of doing this is that you will have a checkpoint to return. In case you mess your script you will be protected from recording everything again. I bet you that we have been many times on that situation. The script was looking good a moment ago. You changed something and now you have no idea of what did you change and now nothing works. No matter what you try you cannot fix it! You are doomed to start all over again.\n\nTalking about your animals, is like having puppies from the original perros that you got. As long as you keep the original ones you will have more puppies! Yay!!! Just leave them alone again with some Wine and Barry White music on the back.\n\nCOMPARISON AND BACKUP\n\nYou will not touch the original files but the copies for the rest of the steps on the post series to come. They are your pristine point of return. You have pairs just to make sure you can compare them with the different data.\n\nLike the proverbial ark you will have a pairs of all the selected animals. That will allow you to populate everything again in the case of a flood. Or any other big catastrophe. Like you erasing a semicolon on the script by accident.\n\nThe scripts that you just recorded may be ugly and dirty for now. Especially if you are dealing with a web solution. Those usually have a lot of stuff going on in the back end. Doesn’t that code just looks like Chinese characters a la Matrix style? Thanks to the double recording, you will be able to find the differences later.\n\nNEXT STEPS\n\nWe will continue with this series making sure we clean up those puppies. Getting them ready to be analyzed. To find the differences on them so we can proceed. So we can do one of the most difficult parts of scripting. CORRELATION.\n\nBut for today I think that is enough. Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/07/24/Script02Pairs/"
      },
    
      {
        "title": "Script03differences",
        "excerpt": "SCRIPTING 03: SPOT DIFFERENCES 2 CORRELATE\n\n\n",
        "content": "SCRIPTING 03: SPOT DIFFERENCES 2 CORRELATE\n\n\n\nNow on the third delivery of the scripting series, we will find a better way to correlate. The technique uses the capacity to spot differences from our two scripts. It is recommended to work on copies of the original two scripts as we mentioned in the last post.\n\nWith the help of comparison software we will be able to spot the differences. From there, we must determine if it is a parameter or a correlation that is needed.\n\nFinally we will know exactly when our script is completely correlated. Every difference on the back end code will be almost transparent. Easier than spotting Wally on those crowded images.\n\nThis gives a ‘fool proof process’ for scripting. It will help you to not to do the rookie mistake. I did that mistake myself on a beginning. I would record only one script and run it until it broke. Then I would try to find where was that it may need a correlation. Try to see if it passes after correlating something. And iterate like that until it finished.\n\nIt was time consuming and a very bad practice. Let’s see this best practice instead.\n\nCHOOSE A COMPARISON TOOL\n\nThe first step is to gather the COPIES of the recorded scripts and run them through a comparison tool. I insist again, use the copies, please.\n\nTo do the comparison there are multiple tools out there. Most probably your scripting tool has a comparison function too! But to my taste I recommend the plugin on notepad++. It is a plugin, so you will need the notepad++ software itself.\n\nMost of the tools will show you the lines where there is a difference. That is cool if your code is not that wide and you can scroll and compare just that line. But the best tools will tell you also the characters that are different.\n\nIt would be like Waldo glowing in those pictures where the multitude confuses you. So many people or characters making it feel like a needle in a haystack. But thanks to this it will be like a glowing, buzzing and 3 feet long needle!\n\nKEEP THE DIFFERENCES MARKED\n\nWhile you compare and search for those differences it is important to keep them all marked for the rest of the steps. Further down the scripting road, you will need to easily identify them.\n\nThis one is quick and easy. But the reason for me to mention it is that it happens often. You loose  where you marked the differences and it makes you pass it again through the scripting tool.\n\nWe want to keep that needle in the haystack glowing and easily identified. Even if we come back for it the next day. Even if you start to change little things keep the markers.\n\nCATALOG THE DIFFERENCES\n\nThe following step will be to identify from the three possible types of differences that you will spot. I define them an those three as they are the most common that you will find. They are:\n\n\n  Parameters\n  Correlations\n  Everything else\n\n\nThe first type is the parameter. This type is all of the information that appears clearly in the recording. You will know them because you are familiar with them by now. You know that you typed certain different user credentials. Or you typed different amounts on a text box. Maybe the amounts that you typed are plainly showing. These are the easier because you will just create a variable for them to be changed while the script executes.\n\nThe second group is for the ones that will require correlation. They are not so easy to identify as they will look like everything that is different. Most of the code with differences will fall into this type. Some times it will be easy to identify as it will look like a value generated by the server that you must catch. Other times it will be just a bunch of crazy characters that you have no idea what they mean or why they are changing. Mark those.\n\nLast, will be everything else. I almost did not create this category, but there are other weird things that fall into this. Such as client generated values, time stamps, uploads and other things that will not always be there. Few of them happen but it is important to mark them. Especially because you must figure a way to generate them later.\n\nThis is teaching you to see in the matrix code the differences. Without seeing the front end of the solution you will see the cute girl in the simulation. Trust me, you will get to a point where you will start to see them by yourself. Here we will tell them apart. Lady in the red dress, lady in black dress, a brunette and a señorita carrying some tacos!\n\nREADY SET GO\n\nNow that you have the differences identified and divided you are ready to move on. The next step on the best practice is the most entertaining one. Some would say the most time consuming as well. Finally you will be ready to correlate and parameterize the script.\n\nBut with the steps we have followed for now, that is going to be way easier than ever. You will have the certainty that your script will never fail. Of course, as long as no one changes the solution.\n\nBut for now we are done. Get ready and for now… Vamonos!\n\n\n\nBesos! &lt;3\n\n-Señor Performo\n",
        "url": "/2017/08/02/Script03Differences/"
      },
    
      {
        "title": "Script04correlations",
        "excerpt": "SCRIPTING 04: HUNTING CORRELATIONS\n\n\n",
        "content": "SCRIPTING 04: HUNTING CORRELATIONS\n\n\n\nOn this post we will examine the process of finding and doing correlations. The best practice has brought you to the core point of the process. This is for most scripting as it focuses on HTTP and other web transfer protocols.\n\nWith this best practice tips you will be able to correlate like a pro. You will be able to identify the exact point where the values are hiding. This will give you the terminator vision that will point exactly where it is; what is around that value; and how to find it. That detection vision may even show you if his boots, jeans and jacket will fit you.\n\nThe best practice will leave your code with all the correlations that it may need. All of this while you get the values really fast. Instead of trying to guess, you will know exactly where are those values. Plus you will get certainty that you are getting them for sure. And the right ones too!\n\nEmpecemos, lets move on to the first step.\n\nSPOT THEM IN THE JUNGLE\n\nYou must star looking for the parameter in the jungle of data that was transferred on the recordings. I call this the jungle of data. A bunch of weird calls and responses that happened between your computer and the server. They are usually HTTP requests and responses. They are saved by most automating tools out there.\n\nYou have the value that you noticed was changing on the recorded script. You must search that value on the communication recorded in between the client and the server.\n\nOnce you find them, create a marker on the exact location. Such as a hunter would do when he finds the nest of his pray.\n\nThis will help you to identify exactly what request generated the response where you need to correlate. Without it maybe you would place the correlations code on the wrong request of your script. Instead, with this you will know exactly where do you have to correlate.\n\nInstead of looking for the prey on the wrong rabbit hole, you will know which one is the one. Where that dang wabbit is hiding! Do not fall into the mistake of looking into the one where you last saw him. He came from beneath!\n\nIDENTIFY THE CORRELATIONS SURROUNDINGS\n\nYou know exactly where is the data appearing for the first time. Now, you must identify what is surrounding it. In the case of HTTP communication it usually has hypertext or tags around. Those are easy to identify.\n\nExample:\n\n&lt;escribo parametro&gt;TACOS&lt;/escribo&gt;\n\nI have marked what is surrounding it that may be the clue to identify it. Of course we want to get TACOS. It is surrounded by parametro&gt; and &lt;/escribo. Take note of the surroundings for the correlations.\n\nAnother may be slightly more complex. It could be part of the hypertext tag. Something like:\n\n&lt;escribo valor=”TACOS“&gt;Pastor con queso&lt;/escribo&gt;\n\nHere they are slightly different but the concept remains the same. Take note that on the left and right of TACOS we have: escribo valor=” and “&gt; . Be aware of the difference. You may wonder why on the left I kept more. I will explain a little more below. But first a third example.\n\nThe communication could be different than regular hypertext tags. Something like:\n\n\n  \n    \n      ØXÌõá£GñùË/½XMLLT?ûÙÏªcGŽVTACOSW¯^ Ù\u000f\u000e\u000fUo¾ùfõƒ\u001fü æÈ¼iëìÙ³±\u0007\u001f&lt;˜µ8þ\n      Ìö_ýõXÇ\u000f?ü°:uêT\n      ~÷îÝX\u0003Ö¥Ì£+þîÜ¹\u0015Ïôýµ¯}­zï½÷ªË—/WG\u001e\n    \n  \n\n\nNow we have our TACOS in between  ûÙÏªcGŽV and W¯^ Ù  . Make sure you know the surroundings of your prey. You will need to locate and cage it in between them. We truly want that head trophy hanging in your wall!\n\nFIND THE BEST HUNT\n\nNow that you know what surrounds your pray you have better chances to hunt it. But we cannot get cocky and hunt for it right away. We must make sure that we can hunt the right one.\n\nAt times the hiding place for our prey will be in between a rock and a palm tree. But there are many other places where that can happen right. If we send hunters and tell them, bring me whats in between the tree and the rock, they may bring anything.\n\nNow that you know the prey is in between the rock and the tree, we must check the jungle again. We must make sure that there are no other confusing trees and rocks.\n\nGo to your recorded HTTP communication. Search for the surroundings you identified. Check on the area after the response that you identified as the good one. If the first find is near your parameter it is awesome.\n\nIf it is not, you may have to keep searching for the next tree and rock, then the next and the next. Do this until you find the right one. Take note of how many rocks and trees you needed to search to find the prey. Later you will be able to say “Find the tacos in between the third rock and the third tree“.\n\nGROUP HUNTS\n\nOn a similar principle, you may be looking at correlating a series of values. This is slightly more complex but falls under the same principle.\n\nImagine you want to hunt a pack of prairie dogs. They will be hiding always in between dirt holes. This one is easier once you identify where are their holes.\n\nYou may see something like this.\n\n__\n\nDuggie\n\nPerro\n\n_Cat_\n\n&lt;/holes&gt;\n\n\n\nHere we will catch at once everything that is in between a hole (no pun intended). So our surroundings will be hole&gt; and &lt;/. Nice and easy a bulk hunt.\n\nREPLACE WHAT IS CAGED\n\nYou have what surrounds your pray on both sides. Now we will proceed to put that on our script.\n\nIdentify the request that generates the parameter that you are looking for. On it indicate that you want to hunt whatever is in between the surroundings that you identified.\n\nThere is no way it can go wrong. You just tell it, it is in between a bush and a pond. The script will hunt for it with precision. You just have to make sure you give precise indications.\n\nIf your value was not the first one, you must tell that to your script. Hey script, would you please hunt for the value that is just on the fourth pond? You can ignore the others.\n\nOn the same way you can tell him to bring everything in between a pond and a bush. Just be careful here. A forest can have so many of them that you may break the script trying to catch so much at once. be wise.\n\nCORRELATIONS DONE\n\nFollow these steps until you have identified and hunted everything on your script. Afterwards, run it to see if it works. Most probably it will run without a problem.\n\nIf there are problems most probably you forgot to hunt for something. Maybe it was not just tacos and you needed to catch tortas!\n\nNext we will replace the parameters. But for now, vamonos!\n\n\n\nBesos&lt;3\n\n-Señor Performo\n",
        "url": "/2017/08/14/Script04Correlations/"
      },
    
      {
        "title": "Script05variables",
        "excerpt": "SCRIPTING 05: WHAT ABOUT VARIABLES?\n\n\n",
        "content": "SCRIPTING 05: WHAT ABOUT VARIABLES?\n\n\n\nWe are going to talk today about the variables and parameters that you will use in your code. After we are done with the correlations from the last post, we will replace the remaining differences with variables . These are different from the correlations in the sense that they are not generated by the server. They are defined in advance by us, the testers.\n\nTo work with them we will first create them. Afterwards we will replace them all over our code, on all the remaining differences found on our two recordings. Last we will define them to make them work differently, depending on what is the nature of the value that we will type.\n\nLets start with the first step.\n\nCREATE THE VARIABLES\n\nWhenever you identify that there is a difference in the code that is not a correlation, most probably it is a variable. You will be able to see it and recognize the plain value that you typed while recording.\n\nFor each one of those differences, you must create a variable.\n\nI recommend you that at a beginning you just create an empty variable. Just name it in a way that easily identifies it. Use names such as UserID, ProductNumber, Password, FlightID, etc. Just have it there ready to be used.\n\nDon’t worry for now about the type of each variable, parameter or however your scripting tool calls it. Just make sure it is a default variable and that it contains the initial value. The value that you used to record it.\n\nCreate them at the beginning of the code of your script, or on the variable creation module. Do this in the way that your scripting tool manages them.\n\nREPLACING VARIABLES\n\nYou have the variables ready. Now we will find where is the value and replace it with the variable.\n\nThis may be the easiest step. You will just comb down your code until you are sure all the remaining differences are changed by the variables.\n\nThis is just like assigning actors to the characters on a theater play. You have the role of Romeo on the play as the main role. You must look for the actor and assign mister Rad Peet to the main role. Then you will go to Juliet. You will assign the role to Meagan Fatz. Follow this until you have all the characters assigned to an actor. After that you will deal with roles, rather than actors.\n\nYou must do this even with the silly roles; trees, clouds and birds need an actor. Make sure you cover them too.\n\nINDICATE THE TYPE OF VARIABLE AND DATA, THEIR ROLE\n\nOnce you have replaced all the data with the variables, you will proceed to define them. We will give them a type if you wish.\n\nThink of this as the archetypes that they will follow on the play. Some examples of archetypes in any story are such as the villain, the wizard, the hero, the damsel in distress, the sidekick, and so on.\n\nHere we will focus on some other types. These are the core of the performance testing practice.\n\n\n  The immortal deity\n  Use It &amp; Loose It (UILI)\n  The Jealous/Loyal\n  Just one for you\n  The unique\n\n\nTHE IMMORTAL DEITY\n\nThis role is the best for a variable. It is like a god. You will be able to use the same value as many times as you want and it will not wear off. This same value can be used ad infinitum, again and again. If you want to put in your script a value in particular, you can use it as many times as you wish. Nothing will happen with it. It will not die no matter how much you use it!\n\nIt is like a God, a deity, so it will be omnipresent, meaning that it can be be everywhere at the same time. It can be used by everyone at the same time if needed. Which is why it makes it so wonderful for a load test. Every virtual user will be able to use that value at the same time. It will be everywhere.\n\nUSE IT ‘N LOOSE IT\n\nThis next one is not so great. Is anything but the opposite to immortal. This one keeps the characteristic that everyone can use it. It is still everywhere, but disappears once someone uses it.\n\nSo in essence this is available to everybody to pick it. But once someone uses it, it is no good to use anymore, by anyone. This type requires you to be careful, as getting new ones may be difficult.\n\nThis is just like a pile of apples in the grocery store. Anyone can pick one, or two, or more. But once you eat that apple, that particular one, it is gone forever into your gut. No one else can ever eat it again and you must work to get more apples.\n\nTHE JEALOUS/LOYAL\n\nThis one has the characteristic of the immortal. The value will never die and you will be able to use it again and again, as many times as you need. But has the disadvantage of being jealous. It can be with only one person at a time, and when it is with that person, no one else can be with it.\n\nThink of this one as a car. All your family can drive that car as many times as they wish. But only one at a time will be able to drive it. If your brother wants to use the car, he has to wait until you are done with it.\n\nThis one is great as it will never die. You just have to be careful of how you manage it to ensure no one tries to use the same value at the same time.\n\nJUST ONE FOR YOU\n\nThis type is available to everybody to use it. Actually everyone has access to each value. But once someone uses it, it is gone… at least for that person. As everybody else may be able to use it. But only once. After that, that is it for that person.\n\nSomething like getting chickenpox when you are a kid. Everyone can get it. It is available for everybody! But once you get it, it is done. You wont be able to get it again. No mater how many chickenpoxy people you hug. Once for you and done.\n\nTHE UNIQUE SPECIAL\n\nThis is the worst data type of them all. It has none of the good qualities of the others. The behavior of it is very possessive as well because once taken, no one else can use it.\n\n\n\nIt is not immortal at all. Once you use it, it is dead. Gone for ever and ever, disappeared, making it the worst of them all. Because we as load testers want to execute the process several times. But if we killed it once we use it, we will need as many new values for each time we plan to run the process.\n\nMaybe we may need more, you know, for those time we fail and must start again.\n\nTHE HAND HOLDERS\n\nThe last is not a classification of the variable itself, but a behavior you can assign to them.\n\nSome data values will be only good if used together with a matching pair of value. A clear example for this is a user and a password. None of them will work if you don’t type the one that matches with another.\n\nTo use them, you must link these special types. You must get their little hands to be held to each other. Make sure they go together always. A variable will follow the behavior of the lead. One of them must wear the pants in the house!\n\nCONCLUSION\n\nAfter you replace the variables in your script’s code, you must define what type are they. By knowing the type, you will be able to configure them accordingly to ensure that they will behave as expected. After you do that, the script will be almost awesome!\n\nThen it will come the time to test the script that you have created to do a test. What?!\n\nHaha yes, your QA process needs to go through QA as well to ensure it has quality. But we will check that next time. This was a long ish post, so for now, Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/10/06/Script05Variables/"
      },
    
      {
        "title": "Script06iterations",
        "excerpt": "SCRIPTING 06: DOING THE REPS (ITERATIONS)\n\n\n",
        "content": "SCRIPTING 06: DOING THE REPS (ITERATIONS)\n\n\n\nThe main goal for a ‘load test automated script‘ is to do the same process several times again and again. In essence to be able to put some reps while working. Just like when you workout, you must repeat the same exercise many times to see the gains.\n\nIn the same way, after we have all the variables on the script, we must validate that the script can repeat several times without having errors. This is known as an iteration. In other words, the script must be able to iterate.\n\nMany load scripters create scripts that fault on some iterations. When they run the test, they already expect to see some errors and warnings from the script. This means that the test is not the best. To avoid this problem and ensure the quality of our scripts, we must follow a process to get them in iterating shape. Just like a workout program, you will get in shape little by little and step by step.\n\nFIRST DAY\n\nOften you will find people in the gym whom are new or haven’t been there in a long time. Most probably, they won’t be back soon because of over working. They will throw to the trash can the membership that they just payed, together with their plan for a better shape. Instead, to ensure that they have a long story of being in shape, they should start little by little. They should do some exercises only once at the beginning.\n\nIn the same way, we should just check that our script completes one run. Do just one process from start to end. Only then you will make sure that the script can complete a cycle without hurting himself. You will see if all the previous work we have done(Correlations, Data, etc.) completes at least once. Hurrah! If you can complete just one tiny run of a workout, you will be able to come back the next day to keep moving on.\n\nGET USED TO THE REPS\n\nYou have passed the first repetition and you found out that you can do it with no pain. You feel comfortable that you have done a good job. Now, it is time to move on and do some repetitions.\n\nLike your script, you will know it works once it completes an iteration. Then you have to make sure it can do more iterations. But as you are still a newbie on the workout scene, you must do the same exercise while you start doing reps.\n\nI usually recommend to go from 3 to 5 iterations. At times I feel wild and let it run for 10 iterations. The difference for now will be that you will use the same variables on each iteration. Do not change anything and make sure you can do the reps. Easy there, don’t hurt yourself.\n\nADD VARIETY\n\nAfter you notice that without much problem you can do the same reps, it is time to add variety to work all of the muscle groups.\n\nDoing the same was good exercise to get your body used to the activity. But now you want to ensure that you get more gains. So now you will cycle each body part on each rep. First work the biceps. After the guns are trained, move on to the chest. Then, you may work out the legs to not to look like Johnny Bravo. Even add  some yoga or stretching at the end. Then you will have a complete workout.\n\nIn the same way, we will add some change to the iterations. Again, we will do at least 3 to 5 reps. But this time we will change the variables on each iteration as we planned them to change.\n\nBy doing this we will get a double hit. First we will make sure that we can change through all the values and the cycle without breaking. Second, we will check that we configured the variables and the thing cycles in the right way.\n\nDIVIDE THE WORKOUT\n\nYou need to divide the workout. First steps firs: do the warm up before you start doing the reps. Then do the reps as many times as you need in your workout program. And after you are done, make sure you stretch to cool down those muscles.\n\nThere will be times when you don’t need to divide the workout. Such as in some yoga sessions where you just do all of the stretching process all the time. In the same way in a script you may need to test the whole thing iterating. That would make this step useless.\n\nMost of the time, the script has to divide its steps. Cut it on the initial piece with what a real user does once in the morning, like logging in. Then put the actions that will iterate during the day of a real life user. Then, at the end do the logoff processes. Such as real life to ensure that you get the best workout possible.\n\nAlthough there are different opinions on when to do this step, some say you could do it after you did the simple reps step. I believe it should be done once you mastered variety. It is up to you.\n\nREPEAT THE REPS\n\nOnce the workout is divided, we will need to do the reps again to get the best results.\n\nRepeat the 3 to 5 iteration on your script after it is split in phases. Make sure that after the first iteration it can return to a safe start point to repeat the iteration again. If it fails, it must be that it is restarting at a point where it cannot do the steps again. If so, go back to the dividing step and check what can it be. Maybe you need to include an earlier screen that you left in the initial phase.\n\nBy doing this you make sure you are not warming up between reps, or doing an exercise at the beginning and forgetting it for the rest of the workout. Make your script to get the best gains and never throw errors nor warnings.\n\nLONG REPS FOR LIFE\n\nNow that you are used to the workout, you just have to keep doing it. You found that you created the perfect workout. Now it is time to make it a lifetime habit. You will be sexy for life ese!\n\nDown the road you may notice that you get tired of it after some time. This will show you that you need to go back and change your routine. The goal is to make sure it is something that sticks forever.\n\nThe next step here is to leave your script running by itself for a given period of time. Forget the reps, now, this time we are in for duration. Put the script in the loading tool and let it run by itself for about 10 minutes so it does as many reps as it can. Here we will validate that the process is good iterating for long periods of time and make sure you can iterate a lot and that the process never fails. This will leave you with a bulletproof script that runs and runs like the battery bunny.\n\n\n\nCLOSING\n\nWhen you make sure that your script can do the needed reps without a problem you will have a script that is is fit and good.\n\nYou don’t want it quitting at the half of its way to a beach body. You will make sure that the script is strong enough to endure a zero error run if you follow these steps.\n\nMake sure that you go through them every time that you are scripting to become a super scripter!\n\nWe have awesome steps now that assure that our script can do the reps. On the next post we will move to the concurrent check.\n\nBut for now, it is time to go. Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/10/16/Script06Iterations/"
      },
    
      {
        "title": "Script07coexist",
        "excerpt": "SCRIPTINGSCRIPTING 07: SO HAPPY TOGETHER\n\n\n",
        "content": "SCRIPTINGSCRIPTING 07: SO HAPPY TOGETHER\n\n\n\nThere is another characteristic for the scripts that we create. They will be simulating different users doing the same process all together at the same time. This is known as concurrency.\n\nJust like moving into a house together, concurrency can bring problems of coexistence. The multiple users doing the same thing at the same time can generate conflicts, especially with the data. There is a chance that the users could collide with each other trying to use the same value of a variable at the same time. Some times that value may be one that the system doesn’t allow to be shared. This will break the iteration of the script(s) colliding. This could even crash all the scripts running that process.\n\nPreviously, we did some actions to ensure that this will not happen. We gave the data the best configurations that we could, so that the virtual users would not crash when using it. Now it is time to test if we configured them in the right way and that we did not miss anything.\n\nMOVE TO THE HOUSE TOGETHER\n\n\n\nThe first step is to move everyone into the house that you will be shared. In this case the scripts will be the people, and the load testing tool will be the house. The system counts as the house as well, but it is more like the actions that you can do in it.\n\nFirst, move the script into the loading tool. Bring the data for each and every piece needed to run. Just like you would do with a moving van. Bring the furniture and personal items that each person will need to coexist in that house.\n\nOnce there, you must assign each person a room. The scripts will receive a similar treatment. You must configure them to be a multiple set of users. You must configure them in special ways that they will run for this validation. First, I recommend you to put 3 to 5 concurrent users running the script that you just created. Those are good enough as 3 to 5 people is what usually lives in a house. Whenever possible aim at a full house of 5.\n\nREPEAT THE TIMES TOGETHER\n\nWe will focus now on running just a few times together to make sure that we do not have initial bumps. Different from what what we did in the last phase, here we will aim towards 10 iterations per virtual user. The higher number of repetitions is because we must make sure that they will not collide or fight for data.\n\nThis execution will have no stops, so avoid wait times in between steps. Configure them to start all at the same time. When you do this, you will increase the chances of them trying to do the same step at the same time.\n\nThis will be just like a house with a full family. They must be fine sharing common places like the kitchen. Everybody can be there doing their thing at the same time in the kitchen.\n\nOther rooms will not allow you to have many people at the same time, like the bathroom. You can have only one person at a time there. Maybe if the family is open enough you could have more people there at once. One person taking a shower while the other gets ready combing their hair and brushing their teeth.\n\nYou must make sure that you were organized enough that the people in the house will respect this personal space.\n\nLONG TIME LIVING THERE\n\nYou have now validated that no one crashes after doing the same process for a few times. Now it is time to let them be that way for a while.\n\nWe will see if they can be left alone in the house for some time. Let them  do their things to check if they don’t fight for the bathroom. Even if you set the rules of behavior, they may respect them at the beginning for a few times. But, you could have trouble in the long run.\n\nAfter a while, there will start fights over a toothbrush. The dad could be in a hurry to get to the office earlier and mess up everyone else’s bathroom schedule.\n\nIn the same way, this can happen to the scripts running concurrently. On the first iterations everything was fine, but after a while the data collides. Maybe your data could not be cycled. Or maybe it is cycling in a way that eventually the virtual users will fight for it.\n\nWe must do a concurrent run based on duration, instead of iterations. This way will ensure there are no issues.\n\nLeave the scripts running for 10 minutes. Start the virtual users at the same time. Leave no waits in between steps and see how well they do in the long run.\n\nFAMILY INTERVENTION TOGETHER\n\n\n\nYou could encounter that the family has issues running any of these trials. If you find this, you must call them back and check the rules to make sure that there will be no fights.\n\nYou may not have been clear enough the first time. You may not have known that there could be a clash. There could be a parts where people would fight each other over something that you did not foresee.\n\nIn the same way, when you run these steps, check for any clash here. If you find any issue you must find out where and why are the virtual users crashing. It could be data configuration. Or it could be that there is no sufficient data for everyone to run. Maybe the process recorded did not take into account the shared spaces.\n\nIn any case, here you must fix any misbehavior and make sure that they will not fight with each other.\n\nRepeat the process until everyone can coexist without any problem for a given period of time. You will ensure that you have a happy home with this current script.\n\nCONCLUSION\n\nWhen you check for concurrency on your script, you will increase the certainty of its quality. This is crucial as this is often a source for problems once the execution starts.\n\nMake sure that the script can coexist without any problem and you will be closer to having a bulletproof execution!\n\nNext we will add some makeup to the script to make sure it looks pretty. We will ensure that it has all the accessories needed. Also that it is behaving exactly as needed.\n\nBut for now it is time to go. Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/11/07/Script07Coexist/"
      },
    
      {
        "title": "Script09tuningtimers",
        "excerpt": "SCRIPTING 09: TUNING THE WAIT TIMERS\n\n\n",
        "content": "SCRIPTING 09: TUNING THE WAIT TIMERS\n\n\n\nWait times in between steps and iterations are vital parts of your script. But they are not so easy to get right. That is why we need to do some tuning on them.\n\nThe wait times will enable your script to act more or less like a real person. We want it to act different than a computer. A computer has the capacity to do the steps at inhuman speeds. As well, it has the capacity to run at exact intervals, so precise that they will seem inhuman as well. To avoid exact intervals we add some randomization to the wait times.\n\nBecause of that randomization,it is tricky to set the wait times right.\n\nHaving good wait times will ensure that your script acts like a human and generates the desired load into the system.\n\nFirst we will add the randomization to the wait times in between steps. Second, we will run them a bit with that wait time to get some estimates on how long it takes to complete an iteration. Once you have that info, we will do some math to find an approximation to the wait values needed in between iterations.\n\nLast, the most fun of all, we will let them run a bit. There we will find out if the math was right. Which almost never is at first. This is because so many random variables at play.\n\nTUNING BECAUSE OF RANDOMIZING\n\n\n\nThe first step is to add some randomization to the wait times in between steps.\n\nMost of the scripting tools have a randomization function integrated. It usually defines the variation in terms of percentage or seconds. The variation is a plus or minus from what you had declared as the wait time value. We do not want those wait times to go crazy even as some real users may do. You should simulate the averages, not a black sheep.\n\nOn previous posts, we settled those values as fixed to 5 or 10 seconds. My recommendation is to set the variation to +/- 10%. Unless the project has specific scope to not to do this.\n\nThis means that if you have 10 seconds as wait time, the script will wait in between 9 and 11 seconds randomly. This will ensure that you do not execute the same step always at the same interval. This will be more realistico!\n\nGATHER THE DURATION OF ONE\n\nAs we added some randomization to our waits we must figure out the average duration of one iteration. The easiest way would be to add all the wait times in between steps and add the response times. That should be an easy one. But given the randomization of the wait times and the uneven response time for each step, it is not that simple.\n\nWe need to find the average duration of a full iteration. Once we add the random behavior, we will repeat the concurrent run like we did in previous posts. This time we are not looking into testing concurrency. We already know that it works well. But this time we just want to know how long it takes on average to complete the process with the wait times included.\n\nLike a test trial for a runner. We will test how we do beforehand, to have an idea how far are we from the record we want to break. Run again the concurrent scenario with 3 to 5 concurrent users. Enable the wait times in between iteration and let it run for 15 minutes.\n\nMake sure that your tool gathers the duration of each iteration. Afterwards you will have a way to calculate on average how long each iteration takes. This is the best estimation as having an exact value is impossible.\n\nTIME TO USE MATH\n\nNow we know how long it takes on average to complete an iteration. With that value in hand we can proceed to calculate how long it requires to wait in between steps to complete the desired number of iterations per unit of time.\n\nFor this lets use an example: Lets say that you need your script to run 10 times per hour. You just found out in the previous exercise that it takes 100 seconds on average to complete an iteration.\n\nThis means that the 10 iterations that you want will take about 1000 seconds.\n\nSubtract those from the number of seconds in an hour. You know, 3600 seconds in one hour. After that operation you will have 2600 remaining seconds.\n\nAs we want 10 iterations we have 9 wait times in between. So nice and easy we will just divide the remaining seconds by 9. The result is: about 288 seconds in between.\n\nFor ease, here is the formula.\n\n\n  IW -&gt; Iteration Wait Time\n  AI -&gt;  Average Iteration duration\n  TI -&gt;  Total Iterations\n\n\nIW= (3600-AI)/(TI-1)\n\nADD ITERATION TIMES\n\nWe will proceed to add the iteration wait duration once we get it from the formula.\n\nThe twist we will add again is that the iteration time should be randomized as well. We must ensure too that the events do not happen so systematically that the test spills fake results.\n\nI recommend a variation with the wait in between iterations just as I suggested for wait times in between the steps. Set the wait time in between iterations to vary +/- 10% of it’s defined value.\n\nFrom the result we’ve got from the example above we defined 288 seconds as the wait between iterations. So we will let it vary from 260 to 316 seconds.\n\nDoing this we will ensure realism.\n\nRUNNING AND TUNING\n\n\n\nThere are so many variables that are not fixed values here. That makes it difficult to get good wait times at first with just math. Especially with so much random variables flying around and unpredictable response times.\n\nTo ensure we got it right and improve if we are off by much we have to run tuning the math. We achieve this by running them and checking how well they do.\n\nRepeat the test run for 3 to 5 users. This time enable wait times in between steps and in between iterations. This time using the new values that you just calculated.\n\nAgain I would recommend to let this run for at least 15 minutes. This will help, to come to an hourly estimate is easier to just multiply your result by 4. Doing this you will know more or less how much is your script really iterating per hour.\n\nIf you have time to do an hour long run that would work even better.\n\nIf you notice that your iterations are far from the estimates you required, proceed tuning the waits in between iterations. Do not change the waits in between steps. I repeat, just the ones in between iterations.\n\nTune and run again until you reach iterations that are equal or slightly higher than what you are aiming for. You should try to make them slightly higher because once you run a full test, they may slow down a tiny bit.\n\nFINALLY\n\nAs you saw, the science of setting the pace to generate defined amounts of load is not exact. It requires tuning and it can vary afterwards.\n\nYou can reach an approximation first with the due diligence and math. But, given the variations in the response time each step may have and the randomization of wait times, it is almost impossible to define wait times exactly.\n\nThe best approach is to run and tune after the math. Run and check how it is doing. After, if you find something off, tune it and re run.\n\nJust like you would do while cooking. You may have followed the recipe by the letter. But while cooking you must taste and add salt as needed.\n\nEnough for today amigos. Now you have scripts that pace perfectly! Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/11/21/Script09TuningTimers/"
      },
    
      {
        "title": "Script08makeup",
        "excerpt": "SCRIPTING 08: MAKEUP AND FINAL TOUCHES\n\n\n",
        "content": "SCRIPTING 08: MAKEUP AND FINAL TOUCHES\n\n\n\nSome of the final steps to do when you are scripting is to add timers and wait commands. They are like makeup for the script so it is prettier and more useful. We must add the timers on the points where there is a step that is interesting to the test. This is essential to the ones that generate communication with the server.\n\nThen we must add as well some wait times. The reason for the wait times is to simulate more realistically how a real user behaves. Instead of just letting the tool create them, we will hold some better control over them by using fixed waits.\n\nBut first, I will tell you why I recommend to do this at the end. This is contrary to what most people and tools advise to do. Lets see why.\n\nWHY NOT MAKEUP AT THE BEGINNING\n\nIt is a common practice to put these makeup steps at the beginning of the scripting process. But to be honest, I am not entirely sure why these are suggested to be done first. Even most of the scripting and recording tools have options to add these while you are recording. I recommend to not to do it that way. That practice sounds bonkers to me!\n\nThis is because,  if you do those steps at the beginning, it can be a huge waste of time. I feel that doing it this way is not optimal  because you will have to repeat these steps if there is any problem while scripting. So, those bits of time you waste creating those timers and waits, will have to be spent again if you have to record the script a second or third time.\n\nI don’t know if you always get a perfect script at the first attempt. I often have to record the whole damn thing again. This is why I think it is better to put the waits and timers only once. So I recommend to add them at the moment that you are sure you are not typing them many times. And that moment is at the end.\n\n\n\nIt is like paying for your groceries before you go to the supermarket. What would happen if the super market doesn’t have the type of tortillas that you already paid for? You would have to cancel the payment and pay again for the ones you found instead. Or cancel the payment at all and loose that time spent paying for something you would not get in the end.\n\nSTART AND END TIMERS\n\nFinally we will proceed to add the timers. First, make sure that you have the list of defined timers together with their names. They must follow a specific naming convention and be available on the test case.\n\nBe careful while you check where to place the timers. The statement that starts the timer must be placed right before the instruction that executes the action that you are timing. Some times, more than one command may be inside the timer. Identify the right ones and and put them all inside.\n\nThere are some instructions in the code of your script that do not talk to the server. We do not care about timing them. Those do a specific action for sure, but they do not require to be timed.\n\nIdentify all the group of instructions that you want to time. Then at the end of that group of instructions place the stop command for that timer. This is also known as the end timer command.\n\nIf you notice that in between the start and end commands there is a wait command, please remove them. Most scripting tools will not count them into the timer results. In essence this means to count the time of the process and add the wait into it, not good. It is better to make sure that you do not have noise in the timer (unintended time counted). We do not want any possible sources of errors.\n\nSIT AND WAIT\n\n\n\nAfter we added the timers, we must proceed to add the wait times. These mean the time that a real human stops to think and do the task at hand. Hence, it is known as well as a think time.\n\nAs mentioned earlier, many scripting tools add these wait time automatically while recording. This I believe is useful if you have the real user recording the script. This is almost never the case. Or maybe you would say you now know well the process. But even as you got familiar with the steps earlier, you cannot act exactly as the real deal.\n\nTo work with this, first we will add the wait commands in between an end and start timer. You must add it after the end of the previous timer and before the start of the next one. Do not ever do this in between the same timer’s start and end. Ensure that you are placing the wait commands out of any timer’s start and end indicators.\n\nLast set the wait times duration to a specific value. If possible set the wait time to a global variable on every timer. In other words, set the wait value to 5 seconds on every place that you decide it has to do so. Or set the global variable to 5 seconds and replace every time value on the waits to the variable. Don’t worry if you feel that the script may go faster or slower than a real user if you do this. Later, we will check that it waits in an adequate way.\n\nTEST THE MAKEUP AGAIN\n\nNow we must make sure that we did not break anything by adding makeup to the script. We do not want to be like the girl that added so much that cannot go out with it. The point is to be able to go out without looking like a clown with so much powder in the face.\n\nRun the script once and make sure it goes through all the steps without a problem. Here you will get for the first time readings of the response times that your timers can catch now. Check that the steps complete and take note for the timers’s results. They may show some performance issues from the beginning. Report to management if you notice any.\n\nIf you completed one run without any problem, move on to the concurrent run. Put them together as we did in the previous post and run 5 of the same for a few minutes. This will ensure the script is still working and you will gather early response times under load. Here you can identify possible early trouble makers.\n\nCONCLUSION\n\nIt is important to be presentable and pretty, such as what you would achieve wearing makeup. If you are too macho lets call it getting tidy, fresh and ready for your lady.\n\nThe same goes to the scripts that you are creating. But instead of adding them at the beginning, it is more reasonable to do it near the end. Put the make up on a few minutes before you leave home. Do not do it as soon as you wake up.\n\nAdd the timers and waiting times to your script at the end. Be careful to not to break the script by doing so. Poop happens and you don’t want it hitting any fan. so, test again your script after adding the makeup and gather early metrics.\n\nNow, with all that we have done, we are close to the end. Now, you almost have a bulletproof script amigo! Next we will try them with other actions to see if they can interact without crashing again.\n\nFor now it is time to go. Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2017/11/28/Script08Makeup/"
      },
    
      {
        "title": "Script10all2gether",
        "excerpt": "SCRIPTING 10: EVERYTHING TOGETHER\n\n",
        "content": "SCRIPTING 10: EVERYTHING TOGETHER\n\n\nThe last step for the scripting best practice series is to test that everything can run together. Our script is almost finished. This step consists of running the script together with all of the scripts in the project.\n\nBecause of this, this last step has to be done until all of the other scripts are ready to be run together. In other words, it has to be done at the end of the creation process of all of the scripts, once the scenario creation process has started. This makes the step to intersect with the scenario creation best practice. But we will talk about that best practice in future posts.\n\nAs you are testing all of the scripts together, You can think it as some sort of small scenario test. Instead, you are doing this step to ensure that the script that you just finished does not collide with other scripts. The goal is to make sure you have no errors on this step. You will have a bulletproof script. Even better, as you will have a bunch of bulletproof scripts,  you will have as well a bulletproof scenario.\n\nLet’s get going and walk through the steps.\n\nTHE POINT EVERYTHING TOGETHER\n\nThe focus of this step is simple. It is to try to see if your script can run for a while, together with the rest of the scripts in the project. In other words, to run with every script on your current project.\n\nOn previous steps of the best practice, you ran multiple people doing the same thing. Now you are going to expand that. You are going to add to the mix, the rest of the scripts as well. In other words, your multiple people doing the same thing together with other people doing other things.\n\nHere you are going to check that such fights and collisions for data will not happen. Those collisions can make a user throw errors on your test or even to fail completely. Similar to the house test we did earlier. There is a bunch of people in the house doing a life and interacting. Just like a family with the same last name in it in the same appartment.\n\n\nBut their apartment is in apartment building. Many different families interacting. Most of them minding their own business, but at times sharing common areas. Such as sharing an elevator, where they must make sure they don’t overload it. Others crossing through the gym while trying to go to the pool. They must make sure to not to step on the ones using the gym.\n\nMake sure they do not collide on those small areas where they may have to interact.\n\nPART OF ANOTHER BEST PRACTICE\n\nSome times, this test may not be done directly by the scripter.\n\nThis step is different in the way its done and in the people included. It has someone that has power over all the scripts contained in the project plan. This because we are running something close to a full load scenario.\n\nMost of the time a test lead will be the one who can put all the scripts together. He will be doing this as part of the best practice for scenario creation. That step is a concurrent script run.\n\nRegardless of this, if the test lead is running this step, the scripters must be present. Or at least, they must be easy to reach. There is the possibility that you could find issues with a script. So, who you’re gonna call?\n\nNot the ghost busters, neither the test lead. You will call the scripter that created the script that has issues. Or the scripters, as usually a collision means that the issue is found in more than one script.\n\nRUN EVERYTHING IN A QUICK MIX\n\nThis step in the best practice will be like throwing everything into a blender. Here we will do a quick everything smoothie.\n\nWe will put three pieces of each ingredient into the blender. Lets create a simple scenario and configure three virtual users with each different script that you have. Prepare them to start all at the same time and set the blender at max speed. This means no wait times in between steps or iterations. We want all of them running as fast as possible.\n\nIn a real load test the scripts should wait in between commands. But on this step we are not aiming at the execution of a load test. We are aiming at testing the test.\n\nSo in order to quickly test if they do not collide, we need them to collide as soon as possible. Put three of each to run as fast as possible for 10 minutes. Let them run for that period of time and check if they can make it.\n\nAgain, this doesn’t focuses on anything on the tested system. This is just about testing the test. Validate that the test can run for a while with no problems for anybody.\n\nFIX IF COLLIDED\n\nIf you find issues with one or more scripts, we should check the problem. The causes could be many, but the most frequentis data collision with another script.\n\n\nHere you must detect if different processes share the same data when they shouldn’t.\n\nThe action to take is going to be different depending on your role. If you are a test lead, you must get the scripters responsible for the scripts together. So that they can talk about the steps of each script and understand where may be the collision to find a fix.\n\nYou could have another situation on which the same scripter did both scripts. This one will be easier as one person has no discussion to do with himself. It will be just figuring out fixes. Although, it may be needed to contact the system users to get clarification on why the collision may be happening.\n\nIf you are the scripter, you just have to contact your peer who developed the other conflicting script. Or just figure out why your script(s) is(are) failing.\n\nAfter the fixes are applied, repeat the quick execution process until you get a flawless execution for ten minutes. To ensure better quality, extend or repeat the time that this test lasts. With these efforts, you will have extra confidence in your scripts. All of the scripts\n\nFINALLY!\n\nBravo amigos! At last, after so many steps and recommendations we are done. We have finally completed all of the steps to ensure that we have flawless scripts. They are ready and sharp like the blade of a samurai. Strong as Hercules resisting any possible challenge.\n\nThe script is in a state that I like to call bulletproof. Ready for everything!\n\nAnd it isn’t just that. Now the script is for sure ready to be run with others. The script is at the point where you can can say with confidence that it will not fail on itself. If there is any error on the execution, you are sure it will come from the tested solution. Not from your script.\n\nThe huge advantage here is that you will know for sure your script does not break. You will get rid forever from the blame some managers try to impose on you saying “for sure what is failing is their test, not our system“.\n\nOh no no no, my scripts are tested for failures. If any problem came it is because the system broke, or worse, because something was changed.\n\nAnd that is it with scripting best practices!\n\nI hope you have enjoyed the series. Please write back if there are any comments and suggestions that you consider should be neat for me to add.\n\nNext we will continue with the scenario creation best practices! But for now, we are done! Vamonos!\n\n\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2018/02/09/Script10All2Gether/"
      },
    
      {
        "title": "Agilejourney",
        "excerpt": "AGILE – MY JOURNEY AND INSIGHTS\n\n\n",
        "content": "AGILE – MY JOURNEY AND INSIGHTS\n\n\n\nMy Agile Journey\n\nAgile got me. Long long time ago, in a Gringo client far far away. It got me from the back and without any warning.\n\nWell, not so long ago. Actually, it was a little bit more than a year ago. But it has been a huge experience.\n\nBefore that, to me agile was a weirdo way of creating software. A way that seemed ridiculous because with the fast paced sprints, it did not leave a chance to do the load tests that I was used to. In general agile was total nonsense to me.\n\nBefore that, I had been only on a few environments that tried to embrace agile. But, for most of them, I was not involved given the nature of my waterfall specialty.\n\nI had to observe agile from a distance. Whenever I was involved, I still was requested to follow the waterfall practices (so ridiculous) and waited for a big time deliverable to script it and do a full performance load test.\n\nOn top of this, most of the agile teams that delivered to me were awful. Not organized at all. And now that I know agile better, they were just wannabes. All of them thinking they were agile but in reality they were just doing mini waterfalls.\n\nBEFORE AGILE, WATERFALL\n\n\n\nBefore agile I only had eyes and beliefs for what I did all of my life as a performance tester. I was following the steps that I have been writing so far on this blog. Most of them – waterfall.\n\nThe thing about a full load test is that you depend completely on the product being almost completed and finalized. It needs to be totally frozen.\n\nYou need a long time learning about the solution. Then, you need time to reverse engineer it. The developers are long gone and encrypted all the code.\n\nIf everything went well, you would have a bunch of automated scripts. Most of them (fr)agile and very dependent on no changes on the system. This gives you a one shot opportunity window. If you miss it and something changes, you may have to start all over again.\n\nThis meant that on a best case scenario, it would take up to 3 weeks to pull off a full performance load test. In a best case scenario.\n\nSadly, this way of doing things was longer than a traditional agile sprint. But, let me say this isn’t wrong. It is impossible to be done “effectively” within a two week sprint. Better said: it could not be done in the way I used to think as “the right way”.\n\nThat is the reason why agile seemed preposterous to me. Not doable due to so many changes happening without time to adapt your scripts.\n\nOn top of that most of waterfall teams were unorganized. There were lots of silos and unbelievable communication problems.\n\nAnd the cherry on the top… There were several companies that were trying agile. They lacked so many things. They had no idea. Not culturally, neither technologically.\n\nEVERYTHING CHANGED. WELCOME TO AGILE\n\nAs I have mentioned earlier, I got to an agile project a little over a year ago. I had little to no agile experience or formal knowledge. I had been pretty much thrown at the fire.\n\nThe experience was interesting. To say the least.\n\n\n\nAgile has some characteristics that work inherently against the traditional way of doing load tests. But at the same time, has some characteristics that enable many interesting things in terms of performance testing.\n\nI will not dwell much in a deep description of agile. But I promise a post about it in the near future.\n\nBut agile’s main component that makes it hard to adapt for a traditional load test is that it is constantly changing. In the time that a scripter has finished to script an automation, it has already changed. Thus, breaking the script(s).\n\nSecond, the solution keeps growing. It doesn’t just change often, but it keeps growing and growing (load and features). This makes the labor of creating and maintaining scripts to grow almost exponentially.\n\nIT IS NOT JUST LOAD TEST ANYMORE\n\nWas it ever?\n\nYeah, a full load test becomes increasingly difficult if you just keep doing things as usual. The maintenance of the automated scripts requires time. That time adds up after all the constant changes. You would hold everyone. That gives them a hard time for both scripting and executing.\n\nThat goes totally against the agile credo. Not very practical even for a hardening sprint. So the question goes: HOW DO WE ASSURE GOOD PERFORMANCE? (Later we can worry about the load)\n\nYou may notice the word assure in bold text. It is not anymore just about testing. Not anymore just about load testing. It is about assuring that the system performs well. It is performance assurance.\n\nTo be able to assure that a system performs and that you know exactly where it doesn’t, you need to change the mindset on how you proceed about it.\n\nThings have changed with agile and so has performance testing assurance. The answer is not automating as much and fast as possible. We need to be smarter about it. Just to stop thinking about the big ass load test we used to do right at the end of the project. Now we have multiple and constant ends on the project. So many moving pieces.\n\nIt is not about the silver bullet automation tool that will magically enable you to script as fast as needed. Or not to scrip at all. That is not possible. Whoever tells you that a tool just by itself will enable you to do agile, might require follow up questions on those fantastic claims. It definitely is not about tools. They may help a bit, but the true answer is elsewhere.\n\nBeware! The changes are coming!\n\nCONCLUSION\n\nAgile brings several challenges to the old art of performance or load testing. Especially because of the fast pace on everything. It keeps growing and that would make the maintenance of a growing pool of automated scripts, impossible.\n\nTo assure good performance the course of action needs to be changed. The old ways will just not work. Stop trying to automate as much as possible and as fast as possible. It is not about a tool. It is about mindsets, culture and cooperation.\n\nI have found several ideas that have helped me to assure performance on agile teams. I will write about them and open a can of worms that will be fun to talk about. But mostly I hope will be helpful and give material for thought. This story will keep going… In two week sprints.\n\nBesos &lt;3\n\n-Señor Performo\n",
        "url": "/2018/09/04/AgileJourney/"
      },
    
      {
        "title": "Whatisagile",
        "excerpt": "WHAT IS THIS AGILE THING\n\n\n",
        "content": "WHAT IS THIS AGILE THING\n\n\n\nAgile is the soup of the day.  For that, I have an urge to describe some of it’s characteristics. The desire to talk about it comes from several experiences I have had lately with many who are so excited about it and trying to embrace it, but in the end, they aren’t becoming… Well…  Agile.\n\nI will talk about some of the characteristics. Some of the misconceptions I have observed around it. This agile fever that sprint by sprint is catching up like wild fire on many environments. But, that sadly for some, it is not having the best symptoms and side effects. Bad results that come from the wrong organizational culture, ignorance or from the way it is being embraced.\n\nIn general, I will try to describe the philosophy of it. Explained to my understanding of it’s key characteristics. Hopefully you will notice if in your workplace it is being embraced with all it’s implications. You don’t want to be the one claiming that you are agile just because you use a Kanban board, do sprints and daily standups, while doing everything else  pretty much in the same way (true story!).\n\nSorry but no talks about performance today. First we need to really understand agile.\n\nWHAT IS AGILE (TO ME).\n\nThere are so many ways that I could describe Agile. But I will try to approach it by what I feel and see it is. Experts may try to lynch me for what I am about to write. But please Mr. Expert, if you want to add something and contribute to my and other’s education I will be more than glad to write a retraction with accurate information based on the comments.\n\nWhat I will write below will not be rules. They are just guidelines of what agile must be. Since being agile is more a journey than a destination. We have no fixed list of attributes. A question exemplifies it better. After how many times going to the gym are you fit and buffed? There is no precise number, but at some point and after acquiring more characteristics, suddenly some will tell you: “Hey you look like the terminator!”\n\nBelow are some of the most important characteristics that I personally think makes you truly agile.\n\nFREQUENT ITERATIONS, RELEASES AND FEEDBACK\n\nYou may be doing sprints in a bi weekly fashion. But that is not what makes you agile. Well, not only a sprinted work fashion by itself.\n\nTo have a true agile project, you should be pushing small new features to your customer as often as possible. In my experience, big bulky one time releases imply you are doing mini waterfalls. All aimed at that big release.\n\nAgile projects can have an end date, but the ability to play with it should be available way before the end date. It should be available pretty much right away after the start of the project,. Starting with a few features. Even just a skeleton, but something to mold and release sprint by sprint.\n\nThe benefit here is that as soon as you have code out, your testers, developers and especially the users can give feedback. Youi will receive several types of feedback. Usability, complaints, functionality, performance and usefulness (utilization). This feedback must not come only from people, but from automated mechanisms that you should have in place to report back to you even before the people does.\n\nSMALL GROUPS OF SPECIALIST POLYMATHS\n\nThe señor Jeff Bezos stated that an optimal agile team should be well fed with two large pizzas. A team of normal eating habits. I could easily chug those two pizzas myself. But what the señor Bezos meant was teams with around 5 to 10 people, not their eating capabilities.\n\nThis small number of people creates an incredible synergy of accountability and cooperation. As a small team, if one person starts to lag, it will drag the whole team.\n\nThe reason for the lag can be varied. But the team will have to step up, distribute work and let someone else help. Everyone should be able to pick up someone else’s work. Even with specialists on the team, they should be able to work on the other areas. The days for the monolingual member are over. There is still a need for specialists. But they must understand hello, hola, bon jour, konnichiwa, guten tag… and so on.\n\nA specialized dev should know automation and database. The scrum master should understand coding and release calls and so on. ‘T-shaped’ is how they are known. The body of the T is their specialty and the head has the other things they can speak and work. Another new type of person is called the E shaped. They have three big legs of knowledge and a common knowledge body. You don’t have to know it all, but at least try to be good at a few more things.\n\nBecause of this, the tester role requires to have some other knowledge than just automation, manual or QA strategies. The QA role, engineer role and even the performance tester role become blurry lines in a group of people who all should know general QA with a well round everything QA engineer.\n\nADAPTATIVE WORK WITHOUT LEFTOVERS\n\nAnother component for the true agile team/project is to assign work, learn and adapt sprint by sprint.  As you move forward, you will learn if your prediction of time for a task was right. Don’t worry if it was bananas at the beginning. You should get better at it sprint by sprint. In the end, you are the one saying how long or much of an effort it will be.\n\nThis eases the team on not biting more than they can chew. But as well forecasts how much can be done from the remaining work. At the same time leaving space for unforeseen tasks.\n\nThe goal is to complete new features and keep moving forward. Technical debt is a spooky term in agile. It also has to be kept in balance. When new features are added, bugs tend to appear, automation tends to break, builds start to fail, and the general entropy principle will keep bringing chaos.\n\nWith this constant chaos appearance, the technical debt will start to creep up and in. Another team duty will be to balance the urge for new feature creation with the constant discipline of keeping technical debt at bay. Even if you to get often a greasy steak and ice cream, you should always have some balance with veggies and fruit. Otherwise you will get in trouble. Too much ice cream can derail your team’s sprint by sprint feature releasing capabilities.\n\nTo clean the chaos constantly was not possible on the old ways. A key characteristic of truly being agile, don’t let the chaos pile until you have it up to your neck.\n\nCONCLUSSION\n\nAgile is a huge mindset change in the IT world. Several were used to the old waterfall methodologies. They are having a hard time letting go the old mindsets. It is crucial that project managers and leaders with traditional mindsets let go many concepts regarding the old ways. Forget about it and LET IT GO.\n\nThe practice consists of small frequent releases to the product. The final user should be able to use parts of the product right away and the team should get all types of feedback from such release. ‘Big-ass once-in-ages releases’ feel to me totally anti agile.\n\nThe teams are small with multidisciplinary people. Having a specialist that can’t do decently a few other tricks might not be the best elements for an agile team. The scrum master or Project lead should definitely be the biggest polymath.\n\nWorkload deficiencies, defects and technical debt should be found and fixed as soon and as automatically as possible. The urge for creation and the need for maintenance must be balanced. In sufficient smart ways that constant change is manageable, chaos should be handled without losing speed in creating new features.\n\nAnd last, Agile is not the new efficiency path to deliver projects. Traditional PM’s and leaders must let go those old mindsets. Agile is not a more efficient way of doing things. It is a more effective way of doing things. If it is  applied well. Since the product generated will be usable while the team keeps working on it, everyone can leverage the use of the product by the clients, to improve, change direction if needed and deliver the best tailor suited solution.\n\nSo for the old ways… Let it go, let it goooooOOO!!\n",
        "url": "/2018/09/20/WhatIsAgile/"
      },
    
      {
        "title": "Perfnotload",
        "excerpt": "PERFORMANCE AND LOAD NOT INTERCHANGEABLE\n\n\n",
        "content": "PERFORMANCE AND LOAD NOT INTERCHANGEABLE\n\n\n\nPerformance and load are different. I am not so uptight about terms and grammar naziing definitions, but I have been for a long time in situations where people try to talk to me about one thing but I understand something completely different. Mostly because one of the parties involved in the conversation lacks the right terms to refer to the topic.\n\n\n\nKinda ironic\n\nWe should all do how Plutarch said (ironically mistranslated), “let’s call a spade a spade, not a gardening tool”.\n\nPeople have been asking me to use the gardening tool, the medical device or even worst a mysterious item referred universally as “the thing”.\n\nAnd to the point that I want to state here, it is a mistake to use the terms ‘Performance Testing’ and ‘Load Testing’ interchangeably. It would be like using ‘Microsoft Office’ and ‘Microsoft Word’ interchangeably. If you do not see the point on that analogy, please read THIS and then come back so I can continue this rant.\n\nWHAT IS PERFORMANCE\n\nThere will be a post dedicated uniquely to describe performance testing as effectively as possible. For now we will say that Performance testing is a QA practice that tries to validate a systems reaction to a use.\n\nThat use could be organic, it could be done by a single user, a single click or even by a developer while writing code.\n\nA performance test is done when you want to see how your system does under a given circumstance. And that circumstance is not always load, spike or stress.\n\nThe most frequent use for a performance test has been changing as the technology and trends have been changing as well. And that frequent use confuses people on what performance testing actually is.\n\nWHY CONFUSED?\n\nOn a beginning performance testing used to be done mostly to model and project capabilities on the hardware for a given use. People used to confuse it, thinking on modeling rather than testing.\n\n\n\nOther times performance testing has been confused with performance optimization. That the focus of the effort was the after thought of polishing the response of a system. But sadly this was another misconception on the terms, a good example would be to confuse programming and debugging.\n\nOn the last iteration (no pun intended) of performance needs, multiple user interaction came up. It started to get difficult to simulate because the number of users to be tested became ridiculously high. This gave birth to the practice of automated load testing which has been the biggest focus lately. Many QA environments have lost focus of the goals for performance testing and blindly dive into load tests thinking that it will be enough to mitigate any performance risk.\n\nLOAD=EXPENSIVE\n\nMany times the QA areas may not really need to do a load test given the risk they are facing. Many may be able to mitigate the risk just by measuring the responses or hardware effects of single user loads or organic loads.\n\nNevertheless they keep attempting to use automation to measure response times and fulfill the true intent of performance testing. Trying to go through with load testing. In some perspective they may be trying to kill a single infantry soldier with a cannon. This is an expensive cannon. Companies are hiring these just because it is being used by everyone else. Some may be justified because they need to defend their fortresses against tanks. Others may be getting cannons cause a salesman said so.\n\nSolving small performance risks with load testing cannons is expensive. Automation for performance requires lots of time, skill, knowledge and smartness to be pulled off. Skills that tend to be expensive per hour on the market. Skills that could be leveraged by a tool which itself is usually super expensive or requires even more skill.\n\n\n\nOn top of that many rely on the automation to tell them some of those response times. Which can get interesting to measure when they face asynchronous processes. Ripley’s believe it or not, many keep trying to measure asynchronous processing time through automation…\n\nFor the last time, Performance testing is not automation or load automation.\n\nCLOSING\n\nPerformance testing is a huge practice and Load testing is a sub set of it. Do not confuse them or use them interchangeably. It could be a mistake to use the terms improperly when a risk you are trying to mitigate may be found in an easy way or missed completely because you went to the wrong approach out of inertia.\n\nPerformance testing means to know how your system is doing in terms of response and hardware under a particular use or scenario. Load testing is, well… Load. A single specific type of use.\n\nBesos &lt;3\n",
        "url": "/2019/03/27/PerfNotLoad/"
      },
    
      {
        "title": "Whattheperf",
        "excerpt": "WHAT IS PERFORMANCE TESTING\n\n\n",
        "content": "WHAT IS PERFORMANCE TESTING\n\n\n\nIt is so silly that I did not start this blog by defining what is performance testing, the core of this whole site. I am so sorry. I got distracted, I guess. Talking about tacos, puppies and talking about my cousin Pepe.\n\nThe world has been confused for so long saying performance testing when they are thinking on a load test. Or even worst thinking that a load test is all there is to performance testing. Or the worst of all, people who just do not know well what it is and goes around using the practice’s name in vain using interchangeably performance optimization, testing, management and all of the other flavors.\n\nSo in all this ramble, lets answer what is performance testing?\n\nDEFINITION\n\nThere are multiple variations of the definition of performance testing. I have not found one that universally accepted. Especially, as the definition gets blurred and confused by the practices that are surrounding performance testing. They are related but are not THE thing, such as performance optimization, capacity planning, tuning and others.\n\nI am going to provide the definition that makes more sense to me. It is based a bit from the one on Wikipedia. But I will rephrase it in my own words and in a way that I think will ease the understanding and this post’s content. So here it goes:\n\n\n  Performance testing:\nA practice or action that consists in the validation and verification of the response’s speed of a computer system ,\n\n  while measuring the impact and reaction of it’s physical components ,\n\n  while being given a particular use.\n\n  -Me\n\n\nThere is an important division that I did on the sentence on purpose. Divided by commas on three pieces with suspiciously long spaces after each. They denote that according to me, performance testing always consists of three parts. No matter what and no matter how, performance testing will have those three. And we will talk about them now.\n\nSPEED\n\nIt is the very thing that everyone thinks of when anyone mentions performance. How fast am I getting a response on this, how long will it take, how long am I willing to wait?\n\nSince speed defines how much distance you travel in a given unit of time, one would think that the important component there is the distance. On computer systems, that distance is the round trip that the data must do from the customer to the database, a more or less fixed measure. Like an Olympic runner for the 100 meters, the distance is fixed, so what measure do we have there then?\n\n\n\nTIME! Key measurement for speed on a system. How much time does it take to complete the process. Generally measured in seconds and/or milliseconds.\n\nTiming a computer process can be done in multiple ways and using many different devices. Examples: count the time that a single local process takes, or the time the information takes to do a round trip, the time each segment of the trip took, or all of the above and even more.\n\nTo measure that time, solutions are vast and diverse. Starting with a silly stop watch or Mississippi counts on the occasions when the observer can easily time it and not to waste resources where you can easily tell that the process is definitely slow. There are internal time measurements that the solution can (or should) provide. Automations can measure response time (Warning, that should not be used as a silver bullet for everything , they can’t measure asynchronous calls). Also with advanced agents, probes, external analysis tools such as APM’s.\n\nNo timing method is universal for all performance testing. The need will call to the right choice to be done when the time comes. (Oh snap… a pun!)\n\nMETRICS\n\n\n\nThe second component for performance testing are the physical things that can be metered. Most of the time, those readings are related to the hardware in charge of your solution. They are usually measured by things called monitors.\n\nThe type of metrics that you can measure are many and varied as well. It is similar to measuring body functions during a fitness test. The metrics that can be measured are many, and will depend on where are you plugging the monitor. What you are looking for, will define the place that you plug it into (ouch).\n\nIn terms of the hardware, the most common place to take metrics is on the solution’s main server. And the most common metrics gathered can be such as CPU, RAM, Network card traffic, processes running and so on. The list can be huge, and you must pick the most transcendent ones for your solution.\n\nBut those are not the only places where you can get info and not the only metrics that you can gather. You must check what may have an impact and/or have use on your solution. Network interfaces, databases, load balancers, cloud interfaces, containers and so on.\n\n\n\nIn the same way, the metrics will be diverse on each one of those. They could even be Celsius if you are metering temperature say in a CPU, a server room or Amazon’s microwave with Alexa. The point here is to see how the metrics jump when you do an action. Just like when a doctor HITS you in the knee with the tiny hammer. How high your knee jumped and how long it took to react.\n\nSpeaking of HITS…\n\nUSE\n\nThe last component of the mix is a specific kind of use. I want to open with a rant that I did in a previous blog post. NOT ALL PERFORMANCE TESTS ARE LOAD TESTS.\n\n\n\nNow that I took that off of my chest, we can proceed with the types of use that you may be interested on. Being specific, this covers circumstances, scenarios or events. Not all scenarios can be covered at once on a single performance test. A performance test focuses on a specific use pattern to be tested and when one more type of use or event is at risk, one more test must be executed.\n\nMultiuser and multi action is a frequent test use requested. Known as load, stress endurance and many other names. All of them are sub-types of performance tests which commonly require load testing tools to be able to generate the load. Please don’t focus the use of load testing tools to gather response times.\n\nThe type of events requiring a performance test are not always load tests (which focus on generating synthetic loads). The type of circumstances or scenarios can be varied. From organic load (generated by real working users), to just process execution (such as scheduled jobs and triggered routines that have no user interaction). There are some that even may require to measure the impact of a single user on the system.\n\n\n\nMany other types of events may require a performance test. Not all of them require load tests or load testing solutions. Make sure that you are testing the right event, given the posed risk factor. That means the situation on which we want to check how our system does. Specifically when those scary events happen.\n\nCLOSING\n\nIn a short sentence: Performance testing is the action of checking response times while monitoring components on a particular event.\n\nAny other definition may be a sub family of performance testing, or may be another performance related action instead of testing (such as tuning, load, optimization, etc.)\n\nNow you know!\n\nBesos &lt;3\n",
        "url": "/2019/04/30/WhatThePerf/"
      },
    
      {
        "title": "Monitoring",
        "excerpt": "MONITORING IS NOT OPTIONAL\n\n\n",
        "content": "MONITORING IS NOT OPTIONAL\n\n\n\nMonitoring is one of the first things I look for when I face a new project or a new system that requires some performance work to be done on it. And surprisingly most of the places, projects and customers that I have visited… do not have it, have misconceptions about it or just plainly do not know what is the deal with it. They are often wrongfully just asking for a load test.\n\nSo to help and enlighten I am going to explain a little why Monitoring is probably one of the most important things you must have to know the performance of your system. It is even more important than just doing plain load tests (I even think it is extremely unwise to run a load test without proper monitoring).\n\nKNOW THYSELF\n\n\n\nOn the awesome book, “Every computer performance book“, Bob Wescott starts the book stating that knowing the current performance of your system is the absolute first step to do anything performance related with it. And I could not agree more with him.\n\nWhat he states as “knowing your system” is a wide statement. It includes knowing utilization patterns, current performance metrics, historical events, and having many logs with lots and lots of data. Data that can be gathered from a well established monitoring setup.\n\nFollowing the syllogism, if all systems should have information about their metrics, and monitoring provides that information, hence, ALL SYSTEMS SHOULD HAVE LOGGED MONITORING.\n\nIn the question of the types of monitoring that should be available I tend to reply that the most complete suite is the best option (more on that below), but in doubt you should have at least something. Anything. Please! To run around not knowing anything about your system is like running around with pointy scissors, driving as drunk and stoned as Charlie Sheen, like running a marathon without tight underwear, like staring at a solar eclipse without glasses, or like doing any of the most reckless thing that you can think of.\n\nBUT ISN’T IT TOO HEAVY?\n\n\n\nThis type of questions or comments make me wonder… what is wrong with you people? (That and thinking that automation is enough to know response times, I know I am weird)… But back to the heavy monitoring question, I get it often. So often that it pretty much became the whole reason for this blog post.\n\nBefore I go on ranting examples on why I think this concern is a bit overblown, being a diligent performance engineer, I must say that yes, indeed monitoring adds some overhead to the performance of the system. That is just the sound of inevitability Mr. Anderson. Such as death, the extra load added by monitoring is a fact of life that has to be dealt with instead of being reckless to avoid it. It would be irresponsible to think that we can avoid death and act like if we could.\n\nMonitoring indeed adds load on the performance of your system to a certain point. But nowadays performance monitoring tools have evolved, server’s power has grown a lot and the extra load is considerably smaller than the user load. It can add up, but with the following examples we will understand that it is better to have it and deal with the extra load than not having it.\n\nEXAMPLES\n\n\n\nA first example. When you skydive you need multiple emergency parachutes system. It would be like saying that having multiple emergency parachute systems is a bit heavy. Let’s jump from the plane or the mountain riff with only one single parachute. That is smart, why should one carry on the extra load?\n\nThe radar and navigation equipment of an airplane is heavy extra weight. The airline wants to be able to cramp up more people than the weight limit the airplane can carry. So why not ditching some of the navigation equipment to put more people and charge more?\n\nAnother. To be able to carry more people again and save some money on equipment, let’s not have that many rescue boats on our cruise ship. Ask Edward John Smith or Thomas Andrews how did that worked out. Would you ride that boat?\n\n\n\nAnother would be the all the meters your car has on the dashboard and the security frame. They add-on gas consumption and weight on your car. But it would be better to not to have them for the sake of savings, something like to go all the Pinto way. Who would not love to have a cheap car with just an inch between bumper and gas tank, no fuel or speed meter and just a gas pedal? I mean you could halt the car just by not accelerating?\n\nWHEN IT MAY BE SKIPPED SKIMMED\n\n\n\nThere are occasions where some of the monitoring may be downgraded but not sipped. As in the last example, some racing high performance cars lack several meters that a conventional car has for the sake of being light and fast. They don’t even have full seats or real lights in front since those special cars race only on daytime. Lots of savings in terms of weight.\n\nOn the other hand, those cars have other extra components that are not found on regular average cars. Special fuel tanks to fill up quickly, nitro boosts and many don’t even use conventional gasoline.\n\nFollowing up the analogy, on extreme conditions, you could skim conventional monitoring. You could choose lighter options, monitor only key elements or have special mechanisms. But still, you need to know something about the system, you should not be blind about it. Driving blind folded is never a good idea.\n\nWHAT TO DO THEN?\n\nThe follow up question is often what to do when the system is maxed out and monitoring may be adding frothing?\n\nThis question has the intent of forcing you to answer suggesting that skipping monitoring is acceptable then. I must shatter that illusion. The plain answer is NO. It should not be the case.\n\n\n\nOpting out of monitoring just to fill up more load is a really bad idea. Such as on the airplane example, what do you do if you have more people than the plane has capacity for? Do you get another plane? Or do you remove all instruments and fly the plane by ear but being able to charge for more people? Which airplane would you choose to fly on? Please, be honest.\n\nThe more you have, the better. As you get more information you are prepared for the world. The more you work, the luckier you will be. Ad an extra layer always.\n\nCONCLUSION\n\n\n\nMonitoring is a crucial part of the art of performance testing. Many people have the wrong idea thinking that you don’t need to monitor and you need only load testing. Today we have awesome things such as APMs on several flavors. The world should not attempt to run without monitors on every environment (dev, test, prod) of your application. The more you know about them, the better!\n\nPlease do not go out running apps without knowing yourself.\n\nBesos &lt;3\n",
        "url": "/2019/06/03/Monitoring/"
      },
    
      {
        "title": "Uivsprotocol",
        "excerpt": "LOAD AUTOMATION – UI vs PROTOCOL\n\n\n",
        "content": "LOAD AUTOMATION – UI vs PROTOCOL\n\n\n\nLately new tools for load test automation have popped out that blur the distinction on the type of automation that they do. The principal types are Protocol or UI. As usual… I feel that this is causing some confusion.\n\nIt is my dutty to try to bring some clarity on the differences and the ups and downs for each. Lets begin!\n\nPERFORMANCE AUTOMATION\n\n\n\nGenerally speaking automation for load testing (not performance) can happen in two forms or types.\n\nPROTOCOL: One of them is the protocol type. This one consists of simulating or forging the communication in between the client and the solution that we are trying to test. It is not something too fancy, it is just a matter of reverse engineering the messages to forge new ones that look similar to the application so it will not distinguish and accept them.\n\nUI: The other one is the UI type. This type doesnt care much about what is being sent to the solution that is being tested. Instead, it’s concerns are with what the user has to do on the client’s front end to interact with the solution. The deal with this one will be mostly to try to figure out how to do the actual clicks or key presses on the front end.\n\nEXAMPLE TIME!\n\nAs usual, in case it was not clear lets use an example so that you will understand better.\n\nIn this example we have a client application and the central server. Think of them as a remote controller and a TV respectively. The remote would be the client application (the UI). The TV will be the server responding to the commands from the application (the remote).\n\nOn this example, automation is a robot that somehow will do the remote’s tasks of sending commands to the TV.\n\n\n\nWelcome back to Señor Roboto.\n\nUI: In the case of an automation at the UI level, Señor Roboto will be configured to be clicking the remote’s actual buttons. He will have to identify the power button, the channel up and down buttons, input, mute and the most frequently used ones. After he identifies them he must try the actions one can do with them, such as to press (click) as indicated to send the command to the TV. It will not care much how that comand is sent.\n\nPROTOCOL: On the other hand, the protocol automation will work very different. Here, Señor roboto will first have infrared transmiters and vision like the Super Hombre. With it he will see what the remote is sending every time a person clicks on it. He will record that signal and learn how to copy it. Then it will send the signal using his transmiter. On this he will have to make sure that the signals he sends are accepted by the TV as if it was the remote who was sending them. He will impersonate the remote.\n\n\n\nADVANTAGES\n\nBoth types of automation have their advantages which bring some benefits to each.\n\n\n\nUI: Generally, the UI automation has some advantages over the protocol type. I think the greatest advantage of the UI automation is that it often gets rid of most CORRELATION needs, making it easier for newbie scripters to automate them. Correlations are often the biggest headaches for protocol scripters which get an easier time through drag and drop automation. Also, this type of automation tends to be a bit mor stable and resilient to back end changes as it focuses on the front end objects that do not change that frequently.\n\nPROTOCOL: The advantages of the protocol automation are, first that it tends to be considerably lighter than the UI automation. Lighter in terms of resources needed by the load generator; such as CPU and RAM. This enables the protocol automation to simulate hundreds (or even thousands) of concurrent threads/vUsers on a single box. As well it gives the scripter some visibility of what is happening internally on the tested application’s communications.\n\nDISADVANTAGES\n\nOn the other hand both types of automation have some disadvantages that the other type counteracts but but also with some more disadvantages of their own.\n\n\n\nUI: This automation is generally heavy in terms of resource utilization. The reason for this is that the automation tool has to render, create or plainly open the application or web browser and renders the whole thing. Just as in our example, Señor Roboto would need many remote controllers. This type of automation is common in functional testing as it is not so much of a hassle automating (even as at times it is). But in load testing is a fatal blow. Some of this tools may allow you to run 2, maybe 3 or even 5 threads or virtual users per computer. Good luck running a test needing a few hundreds or even thousands of threads or virtual users.\n\nPROTOCOL: This automation is considerably lighter than the UI in orders of magnitude. But what it gains in lightness you must pay it in the currency of complexity. The tools simulate the calls which are often in forms of machine code such as HTTP, service calls, binaries and some times even encrypted. To be able to simulate a call the scripter often has to reverse engineer the tested solution. This will make you require a scripter(s) well versed in several IT topics. Not to mention someone good at doing the dreaded correlations and will also need to code stuff. Some may be afraid at this.\n\nDon’t be afraid. Be veeeery afraid! (No, JK, seriously don’t be).\n\nWHICH ONE IS BETTER?\n\nI must give my favorite answer as I do for any good question, IT DEPENDS.\n\nMost of the time I would recommend the protocol automation for load testing, as the load generation process becomes expensive and convoluted through UI when you need to simulate even smallish amounts of threads or users. Not to mention hundreds or even thousands.\n\nDon’t be shy, lazy or afraid. Correlating and forging protocol messages is a beautiful practice, but the name says it. It just needs practice.\n\nBut for the UI side, there are few times where your only option is to simulate through the UI. It may be because the protocol communication is undecipherable, maybe it is proprietary… Or you just do not have a person good at protocol scripting, just beware, this last option will be more expensive in the long term. Just get a good scripter, please. PLEASE!\n\nCONCLUSION\n\nProtocol automation and UI automation are on themselves two very different beasts. The choice on which one to use will depend on the type of testing that you are trying to do. Protocol based testing is the general recomendation for load testing.\n\nIn the few times that it is NOT possible to automate through protocol, UI automation may be used as a last resource.\n\nBesos &lt;3\n",
        "url": "/2019/09/03/UIvsProtocol/"
      },
    
      {
        "title": "Scenariomodeling1",
        "excerpt": "LOAD SCENARIO MODELING 1: ONE PROCESS\n\n\n",
        "content": "LOAD SCENARIO MODELING 1: ONE PROCESS\n\n\n\nModeling scenarios for load tests is not a trivial task. It is not only to blast 100 concurrent virtual users and slam a process. We require to know how hard (often) to hit the processes, with how many threads (vUsers) and for this, how fast each thread should iterate.\n\nAlso, the complexity increases as a load scenario can trigger multiple business processes. It can get complex to try to figure out how to distribute the virtual users among those processes. On top of that, the complexity increases when trying to design the different types of load tests: average load, spike, peak, endurance, etc.\n\nToday I will start explaining the thought process behind the simplest type. How to do load modeling on the iterations, number of users and total load for a single business process.\n\nMAY SOUND SILLY AND SIMPLE\n\n\n\nTo many, this may sound a little bit “duh” or elemental, as the principle actually is a bit straight forward. But as many simple things they don’t sound simple until you see them. At the beginning it sounds evident. But it is hard to figure out on your own. It is like finding out on your own that the amount of water displaced by a submerged object, is the same as it’s volume. Ah duh, no way genius!?\n\nWell, yes way. And the same happens on a load test modeling, with the relation ‘tween totals, iterations and number of users simulated. You would not believe how many places I have been where people don’t seem to be aware of this relation. It is really common. If you don’t have a clear picture of this, don’t be ashamed or worried. I am here to try to make it really clear for you.\n\nYou may even have some notions on this, but not a specific understanding. Or maybe you don’t know the almighty formula for it. Oh yeah, there is a formula. But do not be afraid, it is not a complex one. Once you see it you will not be able to un-see it. It is so simple that it consists of only three little pieces.\n\nTHE LOAD MODELING HOLY TRINITY\n\nAs I mentioned there are three key elements to figure this out when you are load modeling. Often, you will be provided with only two of the three parameters. You will have to calculate the third piece from the other two.\n\n\n\nSo the formula goes a bit like this:\n\nT = U x H\n\nWhere each element means:\n\n\n  T -&gt; Total number of hits per period\n  U -&gt; Number of Users or threads simulated\n  H -&gt; Number of Hits each user does per period\n\n\nAnd that single formula will help you to model most of the scenario needs you may have. Let’s play out a few examples.\n\nNO TOTALS\n\nOne case you may receive only two data tips. 1 – The number of users to simulate. 2 – The approximate number of times each user acts or executes the business process. The project doesn’t care about the total number of actions in a given period of time, just want to simulate what they think is more or less realistic.\n\nIn this case we do not need to do anything to the formula.\n\nExample: You get that the process has 500 concurrent users executing it. Also, on average each user clicks (executes) the process 15 times each hour.\n\nEasy peasy, we have U = 500 and H = 15, then 500 x 15 = 7500\n\nRunning 500 threads (vUsers) that complete 15 iterations per hour will give you approx 7500 hits per hour. That will be the total goal.\n\nNO IDEA HOW FAST\n\nAnother frequent case is when you receive just the total number of hits for that process and the number of concurrent users that must be simulated. Here it won’t matter or be known how fast each user acts.\n\n\n\nOr maybe you need to fix the speed as you have a limited number of threads or users. This is quite common. Be careful if that is the case (full separate post on that).\n\nIn this case we will have to isolate the unknown variable on the formula, H. then we will have H = T / U\n\nQuite simple equation, so let’s run the numbers. The system has 50 concurrent users. The process happens a total of 150 times per hour. Then we divide 150 / 50 = 3. Then, for your simulation you will have to tune the pacing and think times for each script to complete 3 iterations per hour.\n\nDON’T KNOW HOW MANY USERS\n\nThe last possibility is when you receive only how fast a user acts (maybe from the recorded think times) and the total number of hits that the process must receive. This is also common when you have multiple processes on your scenario and must just figure out how to distribute the number of users on each BP.\n\nSo again isolating the unknown variable that we do not have this time is the number of virtual users. U = T / H\n\nIn this example we have that the process executes a total of 200 times per hour. Also that the average user does 5 executions in an hour. Applying the formula we divide 200 / 5 = 40. Using that configuration we should put a total of 40 virtual users or threads.\n\nOn the next post we will analyze further the user distribution.\n\nHAVE ALL THREE\n\n\n\nOccasionally you will have happy times when you have all three and you do not even have to calculate a thing. But beware, as what may seem as happy times may have a hidden plot twist.\n\nThere are times where they will not match. A wild example is that the instruction is to generate 100000 actions per hour in total. This using 10 users, each doing 5 actions per hour. Obviously something here does not add up.\n\nSubstituting on our formula 10 x 5 = 100000…. something CLEARLY does not add up.\n\nThis example is a bit exaggerated to make you notice that the information is very wrong. But at times it will not be so evident. You should always check with the formula. ALWAYS!\n\nCONCLUSION\n\nWhen modeling a load test scenario it is important to keep in mind the holy trinity of metrics for a single process.\n\nT = U x H\n\nAll those three are proportional and should always match with the formula.\n\nAt the same time you can use the formula for if one of them is missing. Or two. Or all the three could be missing! That is a trouble! You may need at least one.\n\nMore to take into account on scenario modeling is how to configure pacing and think times to get the right number of iterations needed for each vuser/thread.\n\nAnother piece will be how to distribute those users on scenarios that have more than one business process.\n\nSo we will continue our modeling multi part series of posts.\n\nBesos &lt;3\n",
        "url": "/2019/10/08/ScenarioModeling1/"
      },
    
      {
        "title": "Joinedgrafanak6",
        "excerpt": "I joined k6!\n\n\n",
        "content": "I joined k6!\n\n\n\nI joined K6\n\nHola! It has been a bit since I last blogged here, but I think it is good to do it regularly again. Especially as I am starting this new journey. I am now a DevRel in the k6 family who advocates for excellent performance practices. In other words, I joined k6! A perfect way to begin this is to tell a story about how I ended up here. I mean, for some, it is no secret that k6 and I have been good friends for a while now. But how exactly did it all start?\n\nA while ago.\n\n\n\nA long, long time ago, in a galax… Ehm… How about: Once upon a time…\n\nFor over 10 years, I was a performance testing and QA consultant providing testing services to multiple organizations, polishing and growing my knowledge and expertise. It all got up to the point that I started to want to share that knowledge.\n\nI created a secret identity to do it. I would wear casual shirts, khakis, and blazers during the day. But at nights, I would wear a fake mustache and start blogging that knowledge, fighting against performance malpractices and ignorance as Señor Performo. Of course, by now, it is not a secret identity anymore. But hey, the costume is not a fake mustache anymore!\n\nThat journey evolved into attending conferences. I gave it a try at ridiculing myself onstage by doing presentations. Then, I even got invited to host my own podcast to rant about performance. \n\nThen, things started to get interesting while I was at some of those European conferences.\n\nPeople!\n\nI met many fantastic people (which I still hang with at least virtually) in those conferences and many other venues. People who also preached the word of the performance practices. Some friends spoke Spanish (among several other languages) and were willing to collaborate for the podcast and many other cool things I have been doing.\n\nI learned a lot with those interactions, growing my knowledge and a better understanding of performance practices and creating better content. That included a boiling interest in ways to create video content. But bouncing tween jobs and the not-so-secret identity was a lot! I was not ready yet.\n\nBut, what I was managing to create was getting attention. I got some more followers and exciting approaches. \n\nOne lucky day, one of those came from k6 in Stockholm, Sweden. They were looking for a person that could help k6 by preaching the word of performance.\n\nI was just a newbie in content creation and was unsure if I would be capable of doing it. But as a coincidence, I had travel arrangements on those days to go Europe (actually to Vienna). Checked how hard would it be to add a Stockholm visit, and there I was, in beautiful Stockholm.\n\nI got a chance to meet the incredible k6 environment and its people. But was still unsure if I could deliver on the need. I mean, I was just a scripter/tester playing at this knowledge-sharing thing. What if I am not good at it? There are bills to pay, cats to feed, and a girlfriend I wanted to propose to.\n\nLet’s collaborate, I said. And that we did here and there over the years. \n\nIn the meantime, I kept polishing my skills and knowledge. At work, I started to use more OSS tools. Got captivated with tool integrations to pipelines, got some chances to use k6, and got enamored at alternatives to visualize my ongoing load tests. Particularly with a tool that I started to use even for personal projects, named Grafana (Woah! Look out! A Checkov’s gun!).\n\nCov-shift-19 happened… A blessing in disguise?\n\nNo one foresaw the upcoming chaos (maybe except Bill Gates), but we all know what happened. The last in-person conference I went to was already giving antibacterial gel swag. My final on-site project was canceled, and I was given early approval to fly back home to be safe.\n\nThe lockdowns started, all work and projects stopped, and furloughs came to be. It was time to polish the content I was already doing, like the podcast’s sound engineering, online presentations, and writing. But there was also a chance at scratching the video content itch.\n\nWe all kinda had to get on video content. Zoom meetings and webinars became the standard. I started doing webinars with a tiny webcam. \n\nThen I borrowed an old camcorder to officially start a YouTube channel. As I was beginning to learn, we had poor quality in terms of video and audio. I began to understand and improve the art of video recording-editing and pairing it with good audio. The possibilities were huge!\n\nI upgraded the camcorder into a Canon M50. I learned a lot about lenses, takes, scenes, audio differences from podcasting, and rudimentary special effects. I loved it! I could die happily doing just that!\n\nI had to get better at it!\n\n\n\nAt events\n\nI kept learning and improving for the next few months. I was learning so much and applied each improvement to my process. Getting better and better.\n\nSuddenly, news came up. Grafana had just acquired k6!\n\nGrafana, the company that made that other tool that I was getting a bit obsessed with (Ha! told ya about the gun!). They had just acquired another product (k6) that seemed to bring so much of the modern best practices I was figuring out!\n\nRight there and then, my mind was blown, thinking about all of the possibilities! Both tools and companies were an incredible complement to each other! I was so happy and could not wait to see what would come from that coalition.\n\nThe moment of truth\n\nAfter a while, I was stunned when I got a heads up that the DevRel position was back. I must admit I froze for a bit. Those cinematic moments when your background zooms out from you. The moment had come to make a decision.\n\nAfter over a decade of doing it, leaving the consultant life behind was a tough decision. But there were so many factors pushing towards doing it and taking the step! A leap of faith!\n\nBut I may say, three main things helped me.\n\nOn the one hand, I already knew good friends and great people in k6. \n\nAdding up, I liked both products. There was so much energy from both being together. \n\nAnd last, I felt more comfortable creating content.\n\nAll right. It was decided. I had to do it.\n\n\n\nOnce decided, I applied. Then started to check information about the company. I kept noticing incredible company culture, environment, energy, and a growing list of attributes as I read. I couldn’t be more excited.\n\nThe adventure begins\n\nIt has already been a few weeks since I joined, and I can already say I made a great decision. But before I begin my babble, I must clarify something. I have not been asked to say anything about what I am about to write. This comes all from the bottom of my soul.\n\nFirst of all, as I already had the feeling, my suspicions were confirmed on my very first day. Both organizations come from different places (from the same country), but each had an incredible culture that mixed perfectly. This includes the pillars and principles of the organization such as transparency, empowerment, open source-ness, high say-do, diversity in perspectives, progress orientation, and fantastic collaboration. I paraphrased them from the company’s site, but trust me, they mean it!\n\nSecond, the way that both solutions mix up drives me crazy! Each is in a growth and development state. k6, and Grafana, both have tremendous potential to keep growing and expanding.\n\nGrafana, on the one hand, is not anymore just the graphing solution I love. It has expanded its functionalities and even extended into other solutions like Loki or Tempo. As well as many different data sources and systems. The team just keeps adding stuff!\n\nk6 (yes, lower case k) is also growing. The performance automation tool continuously adds new features and functionalities with each release. The cloud platform as well is improved frequently. And they have just released a new automation tool that drives browser-based tests! All of it is oriented at developers, who IMO, should be the first line of defense in test automation.\n\nAnd last! They just onboarded a (not so) bad-hombre to help them spread the gospel of the performance assurance best practices!\n\nAs I climb this fantastic new mountain, I just can look at the horizon and be perplexed by the tremendous outlook ahead. The view reaches far, everywhere, and is full of possibilities!\n\nBe prepared for what is soon to come!\n\nBesos &lt;3\n\nSrPerf\n\n\n\nSHARE\n\n[\n\n](https://www.srperf.com/i-joined-k6/#)\n\n[\n\n](https://www.srperf.com/i-joined-k6/#)\n",
        "url": "/2022/01/10/JoinedGrafanaK6/"
      },
    
  
  
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/categories/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/"
  },
  
  {
    "title": "Hola!",
    "excerpt": "\n",
    "content": "\n  Talks - I have presented in some places\n  Linkedin - Connect with me\n  X-Twitter - Follow me\n  Youtube english - Subscribe, like, and activate the bell\n  Youtube español - Subscribete, dale me gusta, y activa la campanita\n  PerfBytes podcasts - Listen on any podcast platform\n  PerfBytes español - Escuchen en cualquier plataforma de podcast\n  Facebook - Like the page and join the groups\n    \n      PerfBytes en español group\n      Performance en español\n    \n  \n  Book - Buy the Hitch Hikers Guide to Load Testing Projects\n\n\nLatest Blog Posts\n\n\n\nJoinedgrafanak6\n\n\n\nScenariomodeling1\n\n\n\nUivsprotocol\n\n\n\nMonitoring\n\n\n\nWhattheperf\n\n\n\n",
    "url": "/"
  },
  
  {
    "title": "About yo",
    "excerpt": "\n",
    "content": "Hola amigos I am el Señor Performo!\n\nI hate to play the IronMan and reveal my secret identity right away. But my name is Leandro Melendez and I am a performance tester born and raised in Mexico City.\n\nI have been working around the testing scene for about 10 years now. All those years constantly crossing the border from Mexico to many cities in the gringo country, the US most of times.\n\nBut fortunately I have crossed more than one border. I have been lucky enough to cook my enchilada in other countries as well. Just haven’t visited them as often as I do it with my amigos gringos.\n\nPlease, don;t stress out. I cross all those borders legally! And now, virtually!\n\nAs a consultant I have had the opportunity to work on performance testing projects on some of the largest companies you can imagine. Also on other not so large companies. But all of them with lots and lots of fun, testing the performance of their IT solutions.\n\nFrom all of those I got lots and lots of stories and learning experiences!\n\nHere, I am going to try to share all of those stories. I will try to tell you many ‘once upon a time’s so that you can live like I did the experiences. Several of them were painful. But the most importante thing that they left me was the learning.\n\nMost of what I want to do with this blog is to my best to share with you all the learning and stories. So that you can get to be a better tester. Specifically a performance one. Be prepared, as I will jump here and there with lessons all over the place.\n\nAt times I will go over topics that relate to other areas. I have been fortunate enough to not only play around performance testing. I will tell you about some of the other crazy testing fields where I have played. Such as: general software testing, project management, development, etc.\n\nAnd who knows, if there is a chance maybe I will add some posts about finance, fitness and cooking. You will find I have several interests and funny stories to share. Who can say no to some new taco recipes?\n\nOn top of that, I am an avid reader. I try to read at least 30 minutes every day. Eventually I will add as well book reviews and many other things. Below you will find as well my good reads feed.\n\nBut back to the blog. To share all the knowledge I have, I will use many crazy examples. I am full of funny ideas, pop references, serious examples, my Mexican family and friends, burritos, enchiladas and of course every possible type of taco.\n\nYou will notice as well, I love to draw mustaches and glasses everywhere.  Who doesn’t?\n\nI hope as well that you will like my crayon like drawings, mustached pictures and silliness. If you dont, please forgive me, I am just trying to make this a joy ride.\n\nTrust me ese! There are a  lot of experience and stories under my hat. OK, sombrero pues.\n\nWelcome to my blog. Mi blog es su blog!\n\nVAMONOS!\n\nBesos &lt;3\n\n-Señor Performo\n",
    "url": "/me/"
  },
  
  {
    "title": "About this website",
    "excerpt": "\n",
    "content": "I’m not sure yet what this website is about, but I’m sure I’ll work it out soon.\n",
    "url": "/podcast/"
  },
  
  {
    "title": "My public speaking experience",
    "excerpt": "\n",
    "content": "Here I am going to try to keep some record of the presentations that I have been given a chance to do. I hope this page grows and grows.\n\n2023\n\n\n  20231110 QualitySense – Keynote – Event page\n  20231018 P99Conf – Talk – Event Page\n  20231001 StarWest – Workshop, Talk, Panel, Coverage – Event Page and My participation\n  20230925 Testing Bolivia – Talk – Event page\n  20230909 HOT – Talk – Event page\n  20230902 BrightestCDMX – Workshop – Event page\n  20230628 HoustonSQEG – Talk – Announcement\n  20230622 Endava Webinars – Talk – Watch Talk\n  20230619 GrafanaCon CDMX – Talk – Watch Talk\n  20230605 AgileDevOpsW – Talk and coverage – Watch Full coverage\n  20230530 QA or the HW – Talk and Panel – Watch Panel\n  20230430 StarEast – Talk, Workshop, Panel, event coverage – Watch whole event coverage\n  20230429 QonfX 23 – Talk – Event link\n  20230331 Crowdar – Talk – Invite -20230328 SG Virtual Conference – Talk – Talk page\n  20230308 Test Automation University Conference – Workshop – Conference page\n  20230221 CMG Impact – Talk – Conference page\n  20230206 Automation Guild – Talk – Event page\n  20230208 PNSQC Jam – Lightning talk – Video\n  20230202 Abstracta Tech Talks – Talk – Presentation video\n  20230116 Synapse QA – Panel – Event video\n\n\n2022\n\n\n  20221209 Quality Sense Talk – TBD\n  20221206 WOPR Paper talk – https://www.performance-workshop.org/wopr29/\n  20221129 Online Test Conf – https://www.onlinetestconf.com/program-otc-2022/\n  20221111 TestingBolivia Talk – https://testingbolivia.com/\n  20221021 ArgenTesting Talk – https://argentesting.com/agenda-2022/\n  20221021 P99Conf Talk – https://www.p99conf.io/agenda/#thursday\n  20221010 PNSQC Portland Keynote, Workshop – https://www.pnsqc.org/leandro_melendez.php\n  20221002 StarWest Anaheim Talk, Panel – https://starwest.techwell.com/program/concurrent-sessions/quest-performance-engineer-tale-adventures-mythical-creature-starwest-2022 https://starwest.techwell.com/program/concurrent-sessions/performance-assurance-and-sre-panel-starwest-2022\n  20220922 GrafanaLive Brazil Talk – https://grafana.com/about/events/\n  20220910 HOT Guadalajara Talk, Workshop – https://handsontesting.com/ https://www.youtube.com/watch?v=MxnyfWFv14Q https://www.youtube.com/watch?v=CsZdMQ4W-lg\n  20220805 Nerdearla Argemntina Talk, interview – https://www.youtube.com/watch?v=xL-IFBpHd0s https://www.youtube.com/watch?v=B4ZBWc-NpUA\n  20220519 AgileActors Grece Webinar – https://www.linkedin.com/feed/update/urn:li:activity:6922464481411231744/?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_all%3ByG%2B7wAl9QLOqaMv1Sjntog%3D%3D\n  20220517 QA or HW present Talk – https://www.qaorthehighway.com/copy-of-speakers\n  20220424 StarEast Orlando FL Keynote, Talk, Panel, Stream – https://conferences.techwell.com/archives/stareast-2022//program/keynotes/qa-ccelerate-stareast-2022.html https://conferences.techwell.com/archives/stareast-2022//program/concurrent-sessions/all-ways-ai-can-be-leveraged-qa-stareast-2022.html https://conferences.techwell.com/archives/stareast-2022//program/concurrent-sessions/modern-performance-assurance-panel-stareast-2022.html\n  20220410 LTB2022 Talk – https://ltb2022.eecs.yorku.ca/\n  20220309 TSQA Talk &amp; Panel – https://tsqa.org/schedule-of-events-tsqa-2022-conference\n  20220208 Test Guild Present Talk – https://guildconferences.com/automation-guild-2022/\n\n\n2021\n\n\n  20211203 Synapse QA Sparks Talk – https://www.youtube.com/watch?v=FfF5ZEOSZyI\n  20211105 – TestingBolivia – El futuro del performance\n  20211023 – TestFlix – Performance impacts\n  20211022 – NatWest QCoE- Modern performance practices\n  20211022 – ArgenTesting – Keynote – La vida de un tester\n  20211008 – StarWest – Keynote – Performance, What is it?\n  20211008 – PAC Fall – The costs of performance assurance\n  20211007 – LoadTestingWorld – Presenting my book on performance\n  20210908 – Hands On Testing – Keynote – Mi libro\n  20210428 – StarEast – ComuniQAte\n  20210406 – Qualitas – Mundo sin testing – La vida sin performance\n  20210325 – Abstracta – Performance Continuo\n  20210323 – PAC Spring – Pipelining automations\n  20210208 – AutomationGuild – Automating the automation\n\n\n2020\n\n\n  202010 TestUY\n  202010 PAC\n  202009 TestTeam\n  202009 STPSept\n  202008 QALatam\n  202007 Sauce\n  202005 Qualitest\n  202005 QALovers\n  202004 STP\n  202003 HOT_QAMinds\n  202002 AutoGuildJoe\n  202002 ISQI\n\n\n2019-10-16 &gt; Mexico City – SrPerf Agile,Testing and performance\n\nGave a presentation on Mexico City sponsored by Load ninja on topics regarding Agile, testing and performance. Explaining how to mix them all.\n\n2019-10-02 &gt; Online – SQA Advisory BeFunctional/Fast/Useful\n\nParticipated on a short introduction describing what is performance testing.\n\n2019-09-25 &gt; Online – Virtual PAC\n\nPresenting about the Pareto principle and using it to optimize the monetary resource utilization while load testing.\n\n2019-05-23 &gt; Online – ArgenTesting\n\nWebinar on Monitoring importance and principles\n\n2019-04-24 &gt; Mexico city, Mexico – QAMinds/Globant\n\nWorkshop-Principles of performance testing\n\nhttps://www.youtube.com/watch?v=p6hShNKnkVc\n\n2019-04-08 &gt; Online – PerfGuild\n\nIPA (Integrated Performance Assurance)\n\nNot public, please register for full presentation.\n\n2019-03-02 &gt; Guadalajara, Mexico – Hands On Testing/QAM\n\nPerformance testing history\n\n2019-02-06 &gt; Chamonix, France – Neotys PAC\n\nSwitching Performance left and right\n\n2019-01-31 &gt; Mexico City, Mexico – TestTalks\n\nPhases or levels on performance testing projects.\n",
    "url": "/presenter/"
  },
  
  {
    "title": "My Youtube Channels",
    "excerpt": "\n",
    "content": "\n\n\n",
    "url": "/youtube/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/page2/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/page3/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/page4/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/page5/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/page6/"
  }
  
]

